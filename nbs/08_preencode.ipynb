{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb36954d",
   "metadata": {},
   "source": [
    "# Pre-encode\n",
    "\n",
    "> Pre-encode images using frozen encoder for faster decoder training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dab59ff",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "This script pre-encodes images using a trained encoder checkpoint, saving the embeddings for faster decoder training.\n",
    "\n",
    "**Usage:**\n",
    "```bash\n",
    "python midi_rae/preencode.py encoder_ckpt=checkpoints/best.pt preencode.output_dir=preencoded/\n",
    "```\n",
    "\n",
    "**TODO:**\n",
    "- May need a simpler Dataset that returns single images (not pairs) + their filenames\n",
    "- Decide on output format: one `.pt` per image, or chunked/batched files?\n",
    "- Add config entries for `encoder_ckpt` path and `preencode.output_dir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873b9860",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp preencode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3a38bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6f3731",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "import hydra\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "from midi_rae.vit import ViTEncoder\n",
    "from midi_rae.data import PRPairDataset  # we'll use use img2 and ignore img1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e40339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@hydra.main(version_base=None, config_path=\"../configs\", config_name=\"config\")\n",
    "def preencode(cfg: DictConfig):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "    print(f\"device = {device}\")\n",
    "    \n",
    "    # Load encoder from checkpoint\n",
    "    ckpt_path = cfg.get('encoder_ckpt', 'checkpoints/best.pt')\n",
    "    print(f\"Loading encoder from {ckpt_path}\")\n",
    "    \n",
    "    model = ViTEncoder(\n",
    "        cfg.data.in_channels, \n",
    "        (cfg.data.image_size, cfg.data.image_size), \n",
    "        cfg.model.patch_size,\n",
    "        cfg.model.dim, \n",
    "        cfg.model.depth, \n",
    "        cfg.model.heads\n",
    "    ).to(device)\n",
    "    \n",
    "    ckpt = torch.load(ckpt_path, map_location=device)\n",
    "    model.load_state_dict(ckpt['model_state_dict'])\n",
    "    model.eval()\n",
    "    \n",
    "    # Output directory\n",
    "    output_dir = Path(cfg.get('preencode', {}).get('output_dir', 'preencoded/'))\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Saving embeddings to {output_dir}\")\n",
    "    \n",
    "    # TODO: May want want a single-image dataset here instead of PRPairDataset\n",
    "    # For now, using PRPairDataset but only encoding img1\n",
    "    for split in ['train', 'val']:\n",
    "        print(f\"\\nProcessing {split} split...\")\n",
    "        ds = PRPairDataset(split=split, max_shift_x=0, max_shift_y=0)\n",
    "        dl = DataLoader(ds, batch_size=cfg.training.batch_size, num_workers=4, shuffle=False)\n",
    "        \n",
    "        all_embeddings = []\n",
    "        all_images = []  # optionally save original images too for reconstruction comparison\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(dl, desc=f\"Encoding {split}\"):\n",
    "                img = batch['img1'].to(device)\n",
    "                z = model(img, return_cls_only=False)  # (B, 65, 768)\n",
    "                all_embeddings.append(z.cpu())\n",
    "                all_images.append(img.cpu())\n",
    "        \n",
    "        # Concatenate and save\n",
    "        embeddings = torch.cat(all_embeddings, dim=0)\n",
    "        images = torch.cat(all_images, dim=0)\n",
    "        \n",
    "        save_path = output_dir / f\"{split}_embeddings.pt\"\n",
    "        torch.save({\n",
    "            'embeddings': embeddings,\n",
    "            'images': images,  # for reconstruction loss computation\n",
    "        }, save_path)\n",
    "        print(f\"Saved {len(embeddings)} embeddings to {save_path}\")\n",
    "        print(f\"  embeddings shape: {embeddings.shape}\")\n",
    "        print(f\"  images shape: {images.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c159f875",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| eval: false\n",
    "if __name__ == \"__main__\" and \"ipykernel\" not in __import__(\"sys\").modules:\n",
    "    preencode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd0c803",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "solveit_dialog_mode": "learning",
  "solveit_ver": 2
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
