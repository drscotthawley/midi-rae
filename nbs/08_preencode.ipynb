{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb36954d",
   "metadata": {},
   "source": [
    "# Pre-encode\n",
    "\n",
    "> Pre-encode images using frozen encoder for faster decoder training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dab59ff",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "This script pre-encodes images using a trained encoder checkpoint, saving the embeddings for faster decoder training.\n",
    "\n",
    "**Usage:**\n",
    "```bash\n",
    "python midi_rae/preencode.py encoder_ckpt=checkpoints/best.pt preencode.output_dir=preencoded/\n",
    "```\n",
    "\n",
    "**TODO:**\n",
    "- May need a simpler Dataset that returns single images (not pairs) + their filenames\n",
    "- Decide on output format: one `.pt` per image, or chunked/batched files?\n",
    "- Add config entries for `encoder_ckpt` path and `preencode.output_dir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873b9860",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp preencode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3a38bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6f3731",
   "metadata": {
    "time_run": "2026-02-10T22:13:01.592542+00:00"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "import hydra\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "from midi_rae.vit import ViTEncoder\n",
    "from midi_rae.data import PRPairDataset  # we'll use use img2 and ignore img1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e40339b",
   "metadata": {
    "time_run": "2026-02-10T22:21:48.222926+00:00"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "@hydra.main(version_base=None, config_path=\"../configs\", config_name=\"config\")\n",
    "def preencode(cfg: DictConfig):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "    print(f\"device = {device}\")\n",
    "    \n",
    "    # Load encoder from checkpoint\n",
    "    ckpt_path = cfg.get('encoder_ckpt', 'checkpoints/enc_best.pt')\n",
    "    print(f\"Loading encoder from {ckpt_path}\")\n",
    "    \n",
    "    model = ViTEncoder(\n",
    "        cfg.data.in_channels, \n",
    "        (cfg.data.image_size, cfg.data.image_size), \n",
    "        cfg.model.patch_size,\n",
    "        cfg.model.dim, \n",
    "        cfg.model.depth, \n",
    "        cfg.model.heads\n",
    "    ).to(device)\n",
    "    \n",
    "    ckpt = torch.load(ckpt_path, map_location=device, weights_only=False)\n",
    "    state_dict = {k.replace('_orig_mod.', ''): v for k, v in ckpt['model_state_dict'].items()}\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "    model.eval()\n",
    "    \n",
    "    # Output directory\n",
    "    output_dir = Path(cfg.get('preencode', {}).get('output_dir', 'preencoded/'))\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Saving embeddings to {output_dir}\")\n",
    "    \n",
    "    for split in ['train', 'val']:\n",
    "        print(f\"\\nProcessing {split} split...\")\n",
    "        ds = PRPairDataset(split=split, max_shift_x=cfg.training.max_shift_x, max_shift_y=cfg.training.max_shift_y)\n",
    "        dl = DataLoader(ds, batch_size=cfg.training.batch_size, num_workers=4, shuffle=False)\n",
    "        \n",
    "        num_chunks = cfg.preencode.num_passes # chunk = 1 pass thru ds\n",
    "        for chunk in range(1,num_chunks+1):\n",
    "            chunk_embeddings = []\n",
    "            chunk_images = []  # optionally save original images too for reconstruction comparison\n",
    "            with torch.no_grad():\n",
    "                for batch in tqdm(dl, desc=f\"Encoding {split}, Chunk {chunk}/{num_chunks}\"):\n",
    "                    img = batch['img2'].to(device)  # img2 come from wider distribution than img1, ignore img1\n",
    "                    z = model(img, return_cls_only=False)  # (B, 65, 768)\n",
    "                    chunk_embeddings.append(z.cpu())\n",
    "                    chunk_images.append(img.cpu())\n",
    "            \n",
    "            # Concatenate and save\n",
    "            embeddings = torch.cat(chunk_embeddings, dim=0)\n",
    "            images = torch.cat(chunk_images, dim=0)\n",
    "            \n",
    "            save_path = output_dir / f\"{split}_embeddings_{chunk}.pt\"\n",
    "            torch.save({\n",
    "                'embeddings': embeddings,\n",
    "                'images': images,  # for reconstruction loss computation\n",
    "            }, save_path)\n",
    "            print(f\"Saved {len(embeddings)} embeddings to {save_path}\")\n",
    "            print(f\"  embeddings shape: {embeddings.shape}\")\n",
    "            print(f\"  images shape: {images.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c159f875",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| eval: false\n",
    "if __name__ == \"__main__\" and \"ipykernel\" not in __import__(\"sys\").modules:\n",
    "    preencode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d19bc7",
   "metadata": {
    "solveit_ai": true,
    "time_run": "2026-02-10T22:22:56.802700+00:00"
   },
   "source": [
    "help me understand this error. I never saw anything like this when I was just training the encoder.\n",
    "```\n",
    "Encoding train, Chunk 1/1000:   0%|                                                                                                                                 | 0/186 [00:00<?, ?it/s]\n",
    "Error executing job with overrides: []\n",
    "Traceback (most recent call last):\n",
    "  File \"/home/shawley/github/midi-rae/midi_rae/preencode.py\", line 59, in preencode\n",
    "    for batch in tqdm(dl, desc=f\"Encoding {split}, Chunk {chunk}/{num_chunks}\"):\n",
    "  File \"/home/shawley/envs/midi-rae/lib/python3.10/site-packages/tqdm/std.py\", line 1181, in __iter__\n",
    "    for obj in iterable:\n",
    "  File \"/home/shawley/envs/midi-rae/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 741, in __next__\n",
    "    data = self._next_data()\n",
    "  File \"/home/shawley/envs/midi-rae/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1548, in _next_data\n",
    "    return self._process_data(data, worker_id)\n",
    "  File \"/home/shawley/envs/midi-rae/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1586, in _process_data\n",
    "    data.reraise()\n",
    "  File \"/home/shawley/envs/midi-rae/lib/python3.10/site-packages/torch/_utils.py\", line 775, in reraise\n",
    "    raise exception\n",
    "IndexError: Caught IndexError in DataLoader worker process 0.\n",
    "Original Traceback (most recent call last):\n",
    "  File \"/home/shawley/envs/midi-rae/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 358, in _worker_loop\n",
    "    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n",
    "  File \"/home/shawley/envs/midi-rae/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n",
    "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
    "  File \"/home/shawley/envs/midi-rae/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 54, in <listcomp>\n",
    "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
    "  File \"/home/shawley/github/midi-rae/midi_rae/data.py\", line 63, in __getitem__\n",
    "    shift_x = random.choice([i for i in range(-self.max_shift_x, self.max_shift_x + 1) if i != 0])\n",
    "  File \"/usr/lib/python3.10/random.py\", line 378, in choice\n",
    "    return seq[self._randbelow(len(seq))]\n",
    "IndexError: list index out of range\n",
    "\n",
    "\n",
    "\n",
    "##### ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ \n",
    "\n",
    "The issue is in this line from your `PRPairDataset`:\n",
    "\n",
    "```python\n",
    "shift_x = random.choice([i for i in range(-self.max_shift_x, self.max_shift_x + 1) if i != 0])\n",
    "```\n",
    "\n",
    "When you pass `max_shift_x=0`, the list comprehension produces an **empty list** (since the only value in the range is 0, which gets filtered out by `if i != 0`). Then `random.choice([])` fails.\n",
    "\n",
    "You're creating the dataset with:\n",
    "```python\n",
    "ds = PRPairDataset(split=split, max_shift_x=0, max_shift_y=0)\n",
    "```\n",
    "\n",
    "The fix would be in `PRPairDataset.__getitem__` to handle the zero-shift case, something like:\n",
    "\n",
    "```python\n",
    "shift_x = 0 if self.max_shift_x == 0 else random.choice([i for i in range(-self.max_shift_x, self.max_shift_x + 1) if i != 0])\n",
    "```\n",
    "\n",
    "(And same for `shift_y`.)\n",
    "\n",
    "Does that make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd0c803",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758e6d72",
   "metadata": {
    "solveit_ai": true,
    "time_run": "2026-02-10T22:23:51.203703+00:00"
   },
   "source": [
    "Oh, we should read the max shift from the configuration file. That was where the encoder was trained. e.g. `cfg.training.max_shift_x` etc\n",
    "\n",
    "##### ğŸ¤–ReplyğŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ ğŸ§ \n",
    "\n",
    "Good idea! Change this line:\n",
    "\n",
    "```python\n",
    "ds = PRPairDataset(split=split, max_shift_x=0, max_shift_y=0)\n",
    "```\n",
    "\n",
    "to:\n",
    "\n",
    "```python\n",
    "ds = PRPairDataset(split=split, max_shift_x=cfg.training.max_shift_x, max_shift_y=cfg.training.max_shift_y)\n",
    "```\n",
    "\n",
    "That way it stays consistent with how the encoder was trained."
   ]
  }
 ],
 "metadata": {
  "solveit_dialog_mode": "learning",
  "solveit_ver": 2
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
