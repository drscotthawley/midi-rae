{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb36954d",
   "metadata": {},
   "source": [
    "# Pre-encode\n",
    "\n",
    "> Pre-encode images using frozen encoder for faster decoder training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dab59ff",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "This script pre-encodes images using a trained encoder checkpoint, saving the embeddings for faster decoder training.\n",
    "\n",
    "**Usage:**\n",
    "```bash\n",
    "python midi_rae/preencode.py encoder_ckpt=checkpoints/best.pt preencode.output_dir=preencoded/\n",
    "```\n",
    "\n",
    "**TODO:**\n",
    "- May need a simpler Dataset that returns single images (not pairs) + their filenames\n",
    "- Decide on output format: one `.pt` per image, or chunked/batched files?\n",
    "- Add config entries for `encoder_ckpt` path and `preencode.output_dir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873b9860",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp preencode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3a38bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6f3731",
   "metadata": {
    "time_run": "2026-02-10T22:13:01.592542+00:00"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "import hydra\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "from midi_rae.vit import ViTEncoder\n",
    "from midi_rae.data import PRPairDataset  # we'll use use img2 and ignore img1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e40339b",
   "metadata": {
    "time_run": "2026-02-10T22:25:57.353170+00:00"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "@hydra.main(version_base=None, config_path=\"../configs\", config_name=\"config\")\n",
    "def preencode(cfg: DictConfig):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "    print(f\"device = {device}\")\n",
    "    \n",
    "    # Load encoder from checkpoint\n",
    "    ckpt_path = cfg.get('encoder_ckpt', 'checkpoints/enc_best.pt')\n",
    "    print(f\"Loading encoder from {ckpt_path}\")\n",
    "    \n",
    "    model = ViTEncoder(\n",
    "        cfg.data.in_channels, \n",
    "        (cfg.data.image_size, cfg.data.image_size), \n",
    "        cfg.model.patch_size,\n",
    "        cfg.model.dim, \n",
    "        cfg.model.depth, \n",
    "        cfg.model.heads\n",
    "    ).to(device)\n",
    "    \n",
    "    ckpt = torch.load(ckpt_path, map_location=device, weights_only=False)\n",
    "    state_dict = {k.replace('_orig_mod.', ''): v for k, v in ckpt['model_state_dict'].items()}\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "    model.eval()\n",
    "    \n",
    "    # Output directory\n",
    "    output_dir = Path(cfg.get('preencode', {}).get('output_dir', 'preencoded/'))\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Saving embeddings to {output_dir}\")\n",
    "    \n",
    "    for split in ['train', 'val']:\n",
    "        print(f\"\\nProcessing {split} split...\")\n",
    "        ds = PRPairDataset(split=split, max_shift_x=cfg.training.max_shift_x, max_shift_y=cfg.training.max_shift_y)\n",
    "        dl = DataLoader(ds, batch_size=cfg.training.batch_size, num_workers=4, shuffle=False)\n",
    "        \n",
    "        num_chunks = cfg.preencode.num_passes # chunk = 1 pass thru ds\n",
    "        for chunk in range(1,num_chunks+1):\n",
    "            chunk_embeddings = []\n",
    "            chunk_images = []  # optionally save original images too for reconstruction comparison\n",
    "            with torch.no_grad():\n",
    "                for batch in tqdm(dl, desc=f\"Encoding {split}, Chunk {chunk}/{num_chunks}\"):\n",
    "                    img = batch['img2'].to(device)  # img2 come from wider distribution than img1, ignore img1\n",
    "                    z, pmask = model(img, return_cls_only=False)  # (B, 65, 768)\n",
    "                    chunk_embeddings.append(z.cpu())\n",
    "                    chunk_images.append(img.cpu())\n",
    "            \n",
    "            # Concatenate and save\n",
    "            embeddings = torch.cat(chunk_embeddings, dim=0)\n",
    "            images = torch.cat(chunk_images, dim=0)\n",
    "            \n",
    "            save_path = output_dir / f\"{split}_embeddings_{chunk}.pt\"\n",
    "            torch.save({\n",
    "                'embeddings': embeddings,\n",
    "                'images': images,  # for reconstruction loss computation\n",
    "            }, save_path)\n",
    "            print(f\"Saved {len(embeddings)} embeddings to {save_path}\")\n",
    "            print(f\"  embeddings shape: {embeddings.shape}\")\n",
    "            print(f\"  images shape: {images.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c159f875",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| eval: false\n",
    "if __name__ == \"__main__\" and \"ipykernel\" not in __import__(\"sys\").modules:\n",
    "    preencode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe7096a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "solveit_dialog_mode": "learning",
  "solveit_ver": 2
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
