{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95dc6903",
   "metadata": {},
   "source": [
    "# viz\n",
    "\n",
    "> vizualization routines\n",
    "\n",
    "\n",
    "**NOTE:** Lazy imports throughout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93157b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1615dcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96051a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import numpy as np\n",
    "import wandb\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349cae58",
   "metadata": {},
   "source": [
    "## UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a164c279",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def cpu_umap_project(embeddings, n_components=3, n_neighbors=15, min_dist=0.1, random_state=42):\n",
    "    \"Project embeddings to n_components dimensions via UMAP (on CPU)\"\n",
    "    import umap\n",
    "    if isinstance(embeddings, torch.Tensor): embeddings = embeddings.detach().cpu().numpy()\n",
    "    reducer = umap.UMAP(n_components=n_components, n_neighbors=n_neighbors, min_dist=min_dist, random_state=random_state)\n",
    "    return reducer.fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d07d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def cuml_umap_project(embeddings, n_components=3, n_neighbors=15, min_dist=0.1, random_state=42):\n",
    "    \"Project embeddings to n_components dimensions via cuML UMAP (GPU)\"\n",
    "    from cuml import UMAP\n",
    "    import cupy as cp\n",
    "    if isinstance(embeddings, torch.Tensor): embeddings = cp.from_dlpack(embeddings.detach())\n",
    "    reducer = UMAP(n_components=n_components, n_neighbors=n_neighbors, min_dist=min_dist, random_state=random_state)\n",
    "    coords = reducer.fit_transform(embeddings)\n",
    "    del reducer\n",
    "    return cp.asnumpy(coords)  # back to numpy for plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cf6f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def umap_project(embeddings, **kwargs): \n",
    "    \"Calls one of two preceding UMAP routines based on device availability.\"\n",
    "    try:\n",
    "        coords = cuml_umap_project(embeddings, **kwargs)\n",
    "    except torch.cuda.OutOfMemoryError:\n",
    "        torch.cuda.empty_cache()\n",
    "        coords = cpu_umap_project(embeddings, **kwargs)\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b28e033",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fef620",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def cuml_pca_project(embeddings, n_components=3):\n",
    "    \"Project embeddings to n_components dimensions via cuML PCA (GPU)\"\n",
    "    from cuml import PCA\n",
    "    import cupy as cp\n",
    "    if isinstance(embeddings, torch.Tensor): embeddings = cp.from_dlpack(embeddings.detach())\n",
    "    coords = PCA(n_components=n_components).fit_transform(embeddings)\n",
    "    return cp.asnumpy(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047d5a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def cpu_pca_project(embeddings, n_components=3):\n",
    "    \"Project embeddings to n_components dimensions via sklearn PCA (CPU)\"\n",
    "    from sklearn.decomposition import PCA\n",
    "    if isinstance(embeddings, torch.Tensor): embeddings = embeddings.detach().cpu().numpy()\n",
    "    return PCA(n_components=n_components).fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf52f98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def pca_project(embeddings, **kwargs):\n",
    "    \"Calls GPU or CPU PCA based on availability\"\n",
    "    try:\n",
    "        return cuml_pca_project(embeddings, **kwargs)\n",
    "    except:\n",
    "        return cpu_pca_project(embeddings, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2f9308",
   "metadata": {},
   "source": [
    "## 3D Plotly Scatterplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5d9cc8",
   "metadata": {
    "time_run": "2026-02-07T02:56:02.111465+00:00"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "def plot_embeddings_3d(coords, num_tokens, color_by='pairs', file_idx=None, title='Embeddings', debug=False):\n",
    "    \"3D scatter plot of embeddings. color_by: 'none', 'file', or 'pair'\"\n",
    "    import plotly.graph_objects as go\n",
    "    n = len(coords)\n",
    "    if debug: print(\" plot_embeddings_3d: n =\",n)\n",
    "    \n",
    "    if color_by == 'none':     colors = ['blue'] * n\n",
    "    elif color_by == 'file':   colors = file_idx.tolist() if file_idx is not None else ['blue'] * n\n",
    "    elif color_by == 'pairs':\n",
    "        n_pairs = n // 2\n",
    "        pair_colors = [f'rgb({np.random.randint(0,256)},{np.random.randint(0,256)},{np.random.randint(0,256)})' for _ in range(n_pairs)]\n",
    "        colors = [pair_colors[i % n_pairs] for i in range(n)]\n",
    "    else: raise ValueError(f\"Unknown color_by: {color_by}\")\n",
    "\n",
    "    hover_text = [f\"fileid: {int(fid)}\" for fid in file_idx] if file_idx is not None else None\n",
    "    \n",
    "    fig = go.Figure(data=[go.Scatter3d(\n",
    "        x=coords[:,0], y=coords[:,1], z=coords[:,2],\n",
    "        mode='markers', \n",
    "        marker=dict(size=4, color=colors, colorscale='Viridis' if color_by != 'pairs' else None, opacity=0.8),\n",
    "        hovertext=hover_text,\n",
    "        hoverinfo='text' if hover_text else 'x+y+z'\n",
    "    )])\n",
    "    title = title + f', n={n}'\n",
    "    fig.update_layout(title=title, margin=dict(l=0, r=0, b=0, t=30))\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f1f471",
   "metadata": {},
   "source": [
    "## Main Routine \n",
    "\n",
    "Calls the preceding routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1feb8ca",
   "metadata": {
    "time_run": "2026-02-07T02:38:06.071644+00:00"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "def _make_emb_viz(zs, epoch, title='Embeddings', do_umap=True, file_idx=None):\n",
    "    \"visualize embeddings, projected\"\n",
    "    fig = None\n",
    "    if do_umap:\n",
    "        coords = umap_project(zs)\n",
    "        fig = plot_embeddings_3d(coords, title=title+f' (UMAP), epoch {epoch}', file_idx=file_idx)\n",
    "    torch.cuda.synchronize() # cleanup before PCA or else you get CUDA errors\n",
    "    gc.collect()\n",
    "    coords = pca_project(zs)\n",
    "    fig2 = plot_embeddings_3d(coords, title=title+f' (PCA), epoch {epoch}', file_idx=file_idx)\n",
    "    if do_umap:\n",
    "        wandb.log({f\"{title} UMAP\": wandb.Html(fig.to_html()), f\"{title} PCA\": wandb.Html(fig2.to_html())}, step=epoch)\n",
    "    else:\n",
    "        wandb.log({f\"{title} PCA\": wandb.Html(fig2.to_html())}, step=epoch)\n",
    "    torch.cuda.synchronize() # cleanup again\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b618d453",
   "metadata": {
    "time_run": "2026-02-07T02:38:17.793054+00:00"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "def _subsample(data, indices, max_points):\n",
    "    \"Subsample data and indices together\"\n",
    "    perm = torch.randperm(len(data))[:max_points]\n",
    "    return data[perm], indices[perm] if indices is not None else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2818edfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def make_emb_viz(zs, model, num_tokens, epoch, title='Embeddings', max_points=8192, pmask=None, file_idx=None):\n",
    "    \"this is the main routine, showing different groups of embeddings\"\n",
    "    device = zs.device\n",
    "    model.to('cpu')\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # CLS tokens\n",
    "    cls_tokens = zs[::num_tokens]\n",
    "    cls_file_idx = file_idx[::num_tokens] if file_idx is not None else None\n",
    "    _make_emb_viz(cls_tokens, num_tokens, epoch, title='CLS Tokens'+title, file_idx=cls_file_idx)\n",
    "    \n",
    "    # Patches (non-CLS)\n",
    "    patch_mask = torch.arange(len(zs)) % num_tokens != 0\n",
    "    patch_only = zs[patch_mask]\n",
    "    patch_file_idx = file_idx[patch_mask] if file_idx is not None else None\n",
    "    \n",
    "    if pmask is not None:\n",
    "        patch_pmask = pmask[:, 1:].flatten().bool()\n",
    "        print(f\"Non-empty patches: {patch_pmask.sum()}/{len(patch_pmask)} ({patch_pmask.float().mean()*100:.1f}%)\")\n",
    "        \n",
    "        # Non-empty patches\n",
    "        valid_patches, valid_file_idx = patch_only[patch_pmask], (patch_file_idx[patch_pmask] if patch_file_idx is not None else None)\n",
    "        rnd_patches, rnd_file_idx = _subsample(valid_patches, valid_file_idx, max_points)\n",
    "        _make_emb_viz(rnd_patches, num_tokens, epoch, title='RND Patches'+title, file_idx=rnd_file_idx)\n",
    "        \n",
    "        # Empty patches\n",
    "        empty_patches, empty_file_idx = patch_only[~patch_pmask], (patch_file_idx[~patch_pmask] if patch_file_idx is not None else None)\n",
    "        rnd_empty, rnd_empty_idx = _subsample(empty_patches, empty_file_idx, max_points)\n",
    "        _make_emb_viz(rnd_empty, num_tokens, epoch, title='RND Empty Patches'+title, do_umap=False, file_idx=rnd_empty_idx)\n",
    "    \n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afde7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "solveit_dialog_mode": "learning",
  "solveit_ver": 2
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
