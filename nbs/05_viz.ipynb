{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95dc6903",
   "metadata": {},
   "source": [
    "# viz\n",
    "\n",
    "> vizualization routines\n",
    "\n",
    "\n",
    "**NOTE:** Lazy imports throughout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93157b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1615dcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96051a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import numpy as np\n",
    "import wandb\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349cae58",
   "metadata": {},
   "source": [
    "## UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a164c279",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def cpu_umap_project(embeddings, n_components=3, n_neighbors=15, min_dist=0.1, random_state=42):\n",
    "    \"Project embeddings to n_components dimensions via UMAP (on CPU)\"\n",
    "    import umap\n",
    "    if isinstance(embeddings, torch.Tensor): embeddings = embeddings.detach().cpu().numpy()\n",
    "    reducer = umap.UMAP(n_components=n_components, n_neighbors=n_neighbors, min_dist=min_dist, random_state=random_state)\n",
    "    return reducer.fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d07d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def cuml_umap_project(embeddings, n_components=3, n_neighbors=15, min_dist=0.1, random_state=42):\n",
    "    \"Project embeddings to n_components dimensions via cuML UMAP (GPU)\"\n",
    "    from cuml import UMAP\n",
    "    import cupy as cp\n",
    "    if isinstance(embeddings, torch.Tensor): embeddings = cp.from_dlpack(embeddings.detach())\n",
    "    reducer = UMAP(n_components=n_components, n_neighbors=n_neighbors, min_dist=min_dist, random_state=random_state)\n",
    "    coords = reducer.fit_transform(embeddings)\n",
    "    del reducer\n",
    "    return cp.asnumpy(coords)  # back to numpy for plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cf6f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def umap_project(embeddings, **kwargs): \n",
    "    \"Calls one of two preceding UMAP routines based on device availability.\"\n",
    "    try:\n",
    "        coords = cuml_umap_project(embeddings, **kwargs)\n",
    "    except torch.cuda.OutOfMemoryError:\n",
    "        torch.cuda.empty_cache()\n",
    "        coords = cpu_umap_project(embeddings, **kwargs)\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b28e033",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fef620",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def cuml_pca_project(embeddings, n_components=3):\n",
    "    \"Project embeddings to n_components dimensions via cuML PCA (GPU)\"\n",
    "    from cuml import PCA\n",
    "    import cupy as cp\n",
    "    if isinstance(embeddings, torch.Tensor): embeddings = cp.from_dlpack(embeddings.detach())\n",
    "    coords = PCA(n_components=n_components).fit_transform(embeddings)\n",
    "    return cp.asnumpy(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047d5a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def cpu_pca_project(embeddings, n_components=3):\n",
    "    \"Project embeddings to n_components dimensions via sklearn PCA (CPU)\"\n",
    "    from sklearn.decomposition import PCA\n",
    "    if isinstance(embeddings, torch.Tensor): embeddings = embeddings.detach().cpu().numpy()\n",
    "    return PCA(n_components=n_components).fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf52f98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def pca_project(embeddings, **kwargs):\n",
    "    \"Calls GPU or CPU PCA based on availability\"\n",
    "    try:\n",
    "        return cuml_pca_project(embeddings, **kwargs)\n",
    "    except:\n",
    "        return cpu_pca_project(embeddings, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2f9308",
   "metadata": {},
   "source": [
    "## 3D Plotly Scatterplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5d9cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def plot_embeddings_3d(coords, color_by='pairs', file_idxs=None, title='Embeddings', debug=False):\n",
    "    \"3D scatter plot of embeddings. color_by: 'none', 'file', or 'pair'\"\n",
    "    import plotly.graph_objects as go\n",
    "    n = len(coords)\n",
    "    if debug: print(\" plot_embeddings_3d: n =\",n)\n",
    "    if color_by == 'none':     colors = ['blue'] * n\n",
    "    elif color_by == 'file':   colors = file_idxs\n",
    "    elif color_by == 'pairs':\n",
    "        n_pairs = n // 2\n",
    "        pair_colors = [f'rgb({np.random.randint(0,256)},{np.random.randint(0,256)},{np.random.randint(0,256)})' for _ in range(n_pairs)]\n",
    "        if debug: \n",
    "            print(pair_colors[:100])\n",
    "            print(\"len(set(pair_colors)) =\",len(set(pair_colors)))\n",
    "        colors = [pair_colors[i % n_pairs] for i in range(n)]\n",
    "\n",
    "    else: raise ValueError(f\"Unknown color_by: {color_by}\")\n",
    "    \n",
    "    fig = go.Figure(data=[go.Scatter3d(\n",
    "        x=coords[:,0], y=coords[:,1], z=coords[:,2],\n",
    "        mode='markers', marker=dict(size=4, color=colors, colorscale='Viridis' if color_by != 'pairs' else None, opacity=0.8)\n",
    "    )])\n",
    "    title = title + f', n={n}'\n",
    "    fig.update_layout(title=title, margin=dict(l=0, r=0, b=0, t=30))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f1f471",
   "metadata": {},
   "source": [
    "## Main Routine \n",
    "\n",
    "Calls the preceding routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1feb8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _make_emb_viz(zs, epoch, title='Embeddings'):\n",
    "    \"visualize embeddings, projected\"\n",
    "    coords = umap_project(zs)\n",
    "    fig = plot_embeddings_3d(coords, title=title+f' (UMAP), epoch {epoch}')\n",
    "    torch.cuda.synchronize() # cleanup before PCA or else you get CUDA errors\n",
    "    gc.collect()\n",
    "    coords = pca_project(zs)\n",
    "    fig2 = plot_embeddings_3d(coords, title=title+f' (PCA), epoch {epoch}')\n",
    "    wandb.log({f\"{title} UMAP\": wandb.Html(fig.to_html()), f\"{title} PCA\": wandb.Html(fig2.to_html())}, step=epoch)\n",
    "    torch.cuda.synchronize() # cleanup again\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b618d453",
   "metadata": {
    "time_run": "2026-02-06T02:35:01.714918+00:00"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "def make_emb_viz(zs, model, num_tokens, epoch, title='Embeddings', max_points=8192, pmask=None):\n",
    "    \"this is the main routine, showing different groups of embeddings\"\n",
    "    device = zs.device\n",
    "    model.to('cpu')\n",
    "    torch.cuda.empty_cache()\n",
    "    cls_tokens = zs[::num_tokens]\n",
    "    _make_emb_viz(cls_tokens, epoch, title='CLS Tokens'+title)\n",
    "    patch_only = zs[torch.arange(len(zs)) % num_tokens != 0] # non-cls tokens \n",
    "    if pmask is not None:\n",
    "        patch_pmask = pmask[:, 1:].flatten()  # exclude CLS column\n",
    "        patch_only = patch_only[patch_pmask.bool()]\n",
    "    rnd_subsample = patch_only[torch.randperm(len(patch_only))[:max_points]]\n",
    "    _make_emb_viz(rnd_subsample, epoch, title='RND Patches'+title)\n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afde7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "solveit_dialog_mode": "learning",
  "solveit_ver": 2
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
