{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95dc6903",
   "metadata": {},
   "source": [
    "# viz\n",
    "\n",
    "> vizualization routines\n",
    "\n",
    "\n",
    "**NOTE:** Lazy imports throughout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93157b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1615dcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96051a7",
   "metadata": {
    "time_run": "2026-02-11T01:29:44.822830+00:00"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import numpy as np\n",
    "import wandb\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349cae58",
   "metadata": {},
   "source": [
    "## UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a164c279",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def cpu_umap_project(embeddings, n_components=3, n_neighbors=15, min_dist=0.1, random_state=42):\n",
    "    \"Project embeddings to n_components dimensions via UMAP (on CPU)\"\n",
    "    import umap\n",
    "    if isinstance(embeddings, torch.Tensor): embeddings = embeddings.detach().cpu().numpy()\n",
    "    reducer = umap.UMAP(n_components=n_components, n_neighbors=n_neighbors, min_dist=min_dist, random_state=random_state)\n",
    "    return reducer.fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d07d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def cuml_umap_project(embeddings, n_components=3, n_neighbors=15, min_dist=0.1, random_state=42):\n",
    "    \"Project embeddings to n_components dimensions via cuML UMAP (GPU)\"\n",
    "    from cuml import UMAP\n",
    "    import cupy as cp\n",
    "    if isinstance(embeddings, torch.Tensor): embeddings = cp.from_dlpack(embeddings.detach())\n",
    "    reducer = UMAP(n_components=n_components, n_neighbors=n_neighbors, min_dist=min_dist, random_state=random_state)\n",
    "    coords = reducer.fit_transform(embeddings)\n",
    "    del reducer\n",
    "    return cp.asnumpy(coords)  # back to numpy for plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cf6f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def umap_project(embeddings, **kwargs): \n",
    "    \"Calls one of two preceding UMAP routines based on device availability.\"\n",
    "    try:\n",
    "        coords = cuml_umap_project(embeddings, **kwargs)\n",
    "    except torch.cuda.OutOfMemoryError:\n",
    "        torch.cuda.empty_cache()\n",
    "        coords = cpu_umap_project(embeddings, **kwargs)\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b28e033",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fef620",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def cuml_pca_project(embeddings, n_components=3):\n",
    "    \"Project embeddings to n_components dimensions via cuML PCA (GPU)\"\n",
    "    from cuml import PCA\n",
    "    import cupy as cp\n",
    "    if isinstance(embeddings, torch.Tensor): embeddings = cp.from_dlpack(embeddings.detach())\n",
    "    coords = PCA(n_components=n_components).fit_transform(embeddings)\n",
    "    return cp.asnumpy(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047d5a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def cpu_pca_project(embeddings, n_components=3):\n",
    "    \"Project embeddings to n_components dimensions via sklearn PCA (CPU)\"\n",
    "    from sklearn.decomposition import PCA\n",
    "    if isinstance(embeddings, torch.Tensor): embeddings = embeddings.detach().cpu().numpy()\n",
    "    return PCA(n_components=n_components).fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf52f98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def pca_project(embeddings, **kwargs):\n",
    "    \"Calls GPU or CPU PCA based on availability\"\n",
    "    try:\n",
    "        return cuml_pca_project(embeddings, **kwargs)\n",
    "    except:\n",
    "        return cpu_pca_project(embeddings, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2f9308",
   "metadata": {},
   "source": [
    "## 3D Plotly Scatterplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5d9cc8",
   "metadata": {
    "time_run": "2026-02-11T01:37:40.395370+00:00"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "def plot_embeddings_3d(coords, num_tokens, color_by='pairs', file_idx=None, title='Embeddings', debug=False):\n",
    "    \"3D scatter plot of embeddings. color_by: 'none', 'file', or 'pair'\"\n",
    "    import plotly.graph_objects as go\n",
    "    n = len(coords)\n",
    "    if debug: print(\" plot_embeddings_3d: n =\",n)\n",
    "    \n",
    "    if color_by == 'none':     colors = ['blue'] * n\n",
    "    elif color_by == 'file':   colors = file_idx.tolist() if file_idx is not None else ['blue'] * n\n",
    "    elif color_by == 'pairs':\n",
    "        n_pairs = n // 2\n",
    "        pair_colors = [f'rgb({np.random.randint(0,256)},{np.random.randint(0,256)},{np.random.randint(0,256)})' for _ in range(n_pairs)]\n",
    "        colors = [pair_colors[i // 2] for i in range(n)]  # pairs are adjacent in index-space \n",
    "    else: raise ValueError(f\"Unknown color_by: {color_by}\")\n",
    "\n",
    "    hover_text = [f\"file_id: {int(fid)}\" for fid in file_idx] if file_idx is not None else None\n",
    "    if color_by == 'pairs':\n",
    "        hover_text = [f\"pair {i//2}\" for i in range(n)] if hover_text is None else [f\"{s}, pair {i//2}\" for i, s in enumerate(hover_text)]\n",
    "\n",
    "    \n",
    "    fig = go.Figure(data=[go.Scatter3d(\n",
    "        x=coords[:,0], y=coords[:,1], z=coords[:,2],\n",
    "        mode='markers', \n",
    "        marker=dict(size=4, color=colors, colorscale='Viridis' if color_by != 'pairs' else None, opacity=0.8),\n",
    "        hovertext=hover_text, hoverinfo='x+y+z+text' if hover_text else 'x+y+z'\n",
    "    )])\n",
    "    title = title + f', n={n}'\n",
    "    fig.update_layout(title=title, margin=dict(l=0, r=0, b=0, t=30))\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f1f471",
   "metadata": {},
   "source": [
    "## Main Routine \n",
    "\n",
    "Calls the preceding routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1feb8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _make_emb_viz(zs, num_tokens, epoch=-1, title='Embeddings', do_umap=True, file_idx=None):\n",
    "    \"visualize embeddings, projected\"\n",
    "    umap_fig = None\n",
    "    if do_umap:\n",
    "        coords = umap_project(zs)\n",
    "        umap_fig = plot_embeddings_3d(coords, num_tokens, title=title+f' (UMAP), epoch {epoch}', file_idx=file_idx)\n",
    "    if torch.cuda.is_available(): torch.cuda.synchronize() # cleanup before PCA or else you get CUDA errors\n",
    "    gc.collect()\n",
    "    coords = pca_project(zs)\n",
    "    pca_fig = plot_embeddings_3d(coords, num_tokens, title=title+f' (PCA), epoch {epoch}', file_idx=file_idx)\n",
    "    if wandb.run is not None: \n",
    "        if do_umap:\n",
    "            wandb.log({f\"{title} UMAP\": wandb.Html(umap_fig.to_html()), f\"{title} PCA\": wandb.Html(pca_fig.to_html())}, step=epoch)\n",
    "        else:\n",
    "            wandb.log({f\"{title} PCA\": wandb.Html(pca_fig.to_html())}, step=epoch)\n",
    "    if torch.cuda.is_available(): torch.cuda.synchronize() # cleanup again\n",
    "    gc.collect()\n",
    "    return pca_fig, umap_fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b618d453",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _subsample(data, indices, max_points):\n",
    "    \"Subsample data and indices together, in pairs\"\n",
    "    perm1 = torch.randperm(len(data)//2)[:max_points//2]\n",
    "    perm2 = perm1 + len(data)//2\n",
    "    perm = torch.cat([perm1,perm2])\n",
    "    return data[perm], indices[perm] if indices is not None else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2818edfa",
   "metadata": {
    "time_run": "2026-02-11T01:30:10.584364+00:00"
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "def make_emb_viz(zs,  \n",
    "                num_tokens, epoch=-1, \n",
    "                model=None, \n",
    "                title='Embeddings', \n",
    "                max_points=5000, \n",
    "                pmask=None, \n",
    "                file_idx=None, \n",
    "                do_umap=True):\n",
    "    \"this is the main routine, showing different groups of embeddings\"\n",
    "    device = zs.device\n",
    "    if model is not None: model.to('cpu')\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    if file_idx is not None and file_idx.shape[0] < zs.shape[0]:\n",
    "        #file_idx = file_idx.repeat(2).repeat_interleave(num_tokens).to(device)\n",
    "        file_idx = file_idx.repeat_interleave(zs.shape[0]//file_idx.shape[0]).to(device)\n",
    "\n",
    "    # CLS tokens\n",
    "    cls_tokens = zs[::num_tokens]\n",
    "    cls_file_idx = file_idx[::num_tokens] if file_idx is not None else None\n",
    "    cls_pca_fig, cls_umap_fig = _make_emb_viz(cls_tokens, num_tokens, epoch=epoch, title='CLS Tokens '+title, file_idx=cls_file_idx, do_umap=do_umap)\n",
    "    \n",
    "    # Patches (non-CLS)\n",
    "    patch_mask = torch.arange(len(zs)) % num_tokens != 0\n",
    "    patch_only = zs[patch_mask]\n",
    "    patch_file_idx = file_idx[patch_mask] if file_idx is not None else None\n",
    "    \n",
    "    if pmask is not None:\n",
    "        patch_pmask = pmask[:, 1:].flatten().bool()\n",
    "        print(f\"Non-empty patches: {patch_pmask.sum()}/{len(patch_pmask)} ({patch_pmask.float().mean()*100:.1f}%)\")\n",
    "        \n",
    "        # Non-empty patches\n",
    "        valid_patches, valid_file_idx = patch_only[patch_pmask], (patch_file_idx[patch_pmask] if patch_file_idx is not None else None)\n",
    "        rnd_patches, rnd_file_idx = _subsample(valid_patches, valid_file_idx, max_points)\n",
    "        patch_pca_fig, patch_umap_fig = _make_emb_viz(rnd_patches, num_tokens, epoch=epoch, title='RND Patches '+title, file_idx=rnd_file_idx, do_umap=do_umap)\n",
    "        \n",
    "        # Empty patches\n",
    "        empty_patches, empty_file_idx = patch_only[~patch_pmask], (patch_file_idx[~patch_pmask] if patch_file_idx is not None else None)\n",
    "        rnd_empty, rnd_empty_idx = _subsample(empty_patches, empty_file_idx, max_points)\n",
    "        empty_pca_fig = _make_emb_viz(rnd_empty, num_tokens, epoch=epoch, title='RND Empty Patches '+title, do_umap=False, file_idx=rnd_empty_idx)\n",
    "    \n",
    "    if model is not None: model.to(device)\n",
    "    figs = {'cls_pca_fig':cls_pca_fig, 'cls_umap_fig':cls_umap_fig, 'patch_pca_fig':patch_pca_fig, 'patch_umap_fig':patch_umap_fig, 'empty_pca_fig': empty_pca_fig}\n",
    "    return figs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b458db6",
   "metadata": {},
   "source": [
    "Testing visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6451ed3",
   "metadata": {
    "skipped": true,
    "time_run": "2026-02-11T01:29:40.480181+00:00"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m",
      "\u001b[32m      3\u001b[39m pio.renderers.default = \u001b[33m'\u001b[39m\u001b[33mnotebook\u001b[39m\u001b[33m'\u001b[39m",
      "\u001b[32m      5\u001b[39m bs, num_tokens, dim = \u001b[32m32\u001b[39m, \u001b[32m65\u001b[39m, \u001b[32m256\u001b[39m",
      "\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m z1 = \u001b[43mtorch\u001b[49m.randn([bs, num_tokens, dim])",
      "\u001b[32m      7\u001b[39m file_idx = torch.arange(bs)",
      "\u001b[32m      8\u001b[39m z2 = z1 +  \u001b[32m0.1\u001b[39m*torch.randn([bs, num_tokens, dim]) \u001b[38;5;66;03m# z2 is slightly shifted from z1\u001b[39;00m",
      "",
      "\u001b[31mNameError\u001b[39m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'notebook'\n",
    "\n",
    "bs, num_tokens, dim = 32, 65, 256\n",
    "z1 = torch.randn([bs, num_tokens, dim])\n",
    "file_idx = torch.arange(bs)\n",
    "z2 = z1 +  0.1*torch.randn([bs, num_tokens, dim]) # z2 is slightly shifted from z1\n",
    "\n",
    "#zs = torch.cat([z1, z2], dim=0).view(-1, dim)  # flatten to [64*65, 256]\n",
    "zs = torch.stack([z1, z2], dim=1).reshape(-1, z1.shape[-1])\n",
    "\n",
    "file_idx = file_idx.repeat_interleave(zs.shape[0]//file_idx.shape[0])  \n",
    "\n",
    "pmask = torch.ones([2*bs, num_tokens])  # all ones\n",
    "pmask[:, 30:] = 0  # mark roughly half the patches as empty\n",
    "\n",
    "figs = make_emb_viz(zs,  num_tokens, title='testing', pmask=pmask, file_idx=file_idx, do_umap=False) \n",
    "figs['patch_pca_fig'].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afde7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "solveit_dialog_mode": "learning",
  "solveit_ver": 2
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
