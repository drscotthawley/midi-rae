{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "858e5fac",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> Core data structures for midi-rae: PatchState and HierarchicalPatchState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c91658f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcb0d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b4c5d6",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "These dataclasses bundle patch embeddings with their spatial and mask metadata,\n",
    "replacing scattered positional return values and manual mask indexing throughout the codebase.\n",
    "\n",
    "### `PatchState`\n",
    "Holds a set of patch embeddings at a single spatial scale, along with their grid positions\n",
    "and masks. Provides convenience properties for common operations like filtering visible patches.\n",
    "\n",
    "### `HierarchicalPatchState`\n",
    "A list of `PatchState` objects ordered **coarsest → finest** (index 0 = global/CLS level).\n",
    "Currently used with two levels (CLS + patches), designed to extend to Swin-style multi-scale later.\n",
    "\n",
    "### `EncoderOutput`\n",
    "Full encoder output bundling the hierarchical patch states with the full (pre-MAE-masking)\n",
    "positions and masks needed by the decoder for reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96051a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d2e3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class PatchState:\n",
    "    \"\"\"Bundle of patch embeddings at a single spatial scale with their metadata.\n",
    "\n",
    "    Attributes:\n",
    "        emb: (B, N, dim) patch embeddings\n",
    "        pos: (N, 2) grid coordinates (row, col) for each patch\n",
    "        non_empty: (B, N) content mask — 1 where patch has content (e.g. notes), 0 for empty\n",
    "        mae_mask: (N,) MAE visibility mask — 1=visible, 0=masked out for reconstruction\n",
    "    \"\"\"\n",
    "    emb: torch.Tensor\n",
    "    pos: torch.Tensor\n",
    "    non_empty: torch.Tensor\n",
    "    mae_mask: torch.Tensor\n",
    "\n",
    "    @property\n",
    "    def visible(self):\n",
    "        \"\"\"New PatchState filtered to only MAE-visible patches\"\"\"\n",
    "        m = self.mae_mask.bool()\n",
    "        return PatchState(\n",
    "            emb=self.emb[:, m],\n",
    "            pos=self.pos[m],\n",
    "            non_empty=self.non_empty[:, m],\n",
    "            mae_mask=self.mae_mask[m],\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def masked(self):\n",
    "        \"\"\"New PatchState filtered to only MAE-masked patches\"\"\"\n",
    "        m = ~self.mae_mask.bool()\n",
    "        return PatchState(\n",
    "            emb=self.emb[:, m],\n",
    "            pos=self.pos[m],\n",
    "            non_empty=self.non_empty[:, m],\n",
    "            mae_mask=self.mae_mask[m],\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def non_empty_flat(self):\n",
    "        \"\"\"Flat bool mask for non-empty patches — useful for loss computation\"\"\"\n",
    "        return self.non_empty.reshape(-1).bool()\n",
    "\n",
    "    @property\n",
    "    def dim(self): return self.emb.shape[-1]\n",
    "\n",
    "    @property\n",
    "    def num_patches(self): return self.emb.shape[1]\n",
    "\n",
    "    @property\n",
    "    def batch_size(self): return self.emb.shape[0]\n",
    "\n",
    "    def to(self, device):\n",
    "        return PatchState(emb=self.emb.to(device), pos=self.pos.to(device), non_empty=self.non_empty.to(device), mae_mask=self.mae_mask.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e2f3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class HierarchicalPatchState:\n",
    "    \"\"\"Multi-scale patch states, ordered coarsest → finest (currently: [0]=CLS, [1]=spatial patches).\n",
    "\n",
    "    Attributes:\n",
    "        levels: List of `PatchState`, one per scale\n",
    "\n",
    "    Note: enc_out.patches[i] and enc_out.patches.levels[i] are equivalent\n",
    "    \"\"\"\n",
    "    levels: list\n",
    "\n",
    "    def __getitem__(self, idx): return self.levels[idx] # get item pull from levels\n",
    "    def __len__(self): return len(self.levels)\n",
    "\n",
    "    @property\n",
    "    def coarsest(self): return self.levels[0]\n",
    "\n",
    "    @property\n",
    "    def finest(self): return self.levels[-1]\n",
    "\n",
    "    @property\n",
    "    def num_levels(self): return len(self.levels)\n",
    "\n",
    "    @property\n",
    "    def all_emb(self):\n",
    "        \"\"\"Concatenate embeddings from all levels along token dim\"\"\"\n",
    "        return torch.cat([level.emb for level in self.levels], dim=1)\n",
    "\n",
    "    @property \n",
    "    def all_non_empty(self):\n",
    "        \"concatenate non-empty patches at all levels\" \n",
    "        return torch.cat([level.non_empty for level in self.levels], dim=1)\n",
    "\n",
    "    def to(self, device):\n",
    "        return HierarchicalPatchState(levels=[x.to(device) for x in self.levels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f2a3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class EncoderOutput:\n",
    "    \"\"\"Full encoder output.\n",
    "\n",
    "    Attributes:\n",
    "        patches: Encoded representations (visible patches only)\n",
    "        full_pos: (N_full, 2) all grid positions before MAE masking (needed by decoder)\n",
    "        full_non_empty: (B, N_full) all content masks before MAE masking\n",
    "        mae_mask: (N_full,) the MAE mask applied (1=visible, 0=masked)\n",
    "    \"\"\"\n",
    "    patches: HierarchicalPatchState\n",
    "    full_pos: torch.Tensor\n",
    "    full_non_empty: torch.Tensor\n",
    "    mae_mask: torch.Tensor\n",
    "\n",
    "def to(self, device):\n",
    "        return EncoderOutput( patches=self.patches.to(device), full_pos=self.full_pos.to(device), \n",
    "                              full_non_empty=self.full_non_empty.to(device), mae_mask=self.mae_mask.to(device) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bd4329",
   "metadata": {},
   "source": [
    "### Sample usage\n",
    "\n",
    "**Encoder returns `EncoderOutput` containing a `HierarchicalPatchState`:**\n",
    "```python\n",
    "enc_out = encoder(img, mask_ratio=0.5)\n",
    "\n",
    "# Access the patch hierarchy\n",
    "cls_state = enc_out.patches.coarsest    # PatchState with CLS token\n",
    "patch_state = enc_out.patches.finest    # PatchState with patch embeddings\n",
    "```\n",
    "\n",
    "**Working with PatchState — filtering, shapes, masks:**\n",
    "```python\n",
    "ps = enc_out.patches.finest\n",
    "\n",
    "ps.emb          # (B, N_visible, dim) — patch embeddings\n",
    "ps.pos          # (N_visible, 2) — grid coordinates (row, col)\n",
    "ps.non_empty    # (B, N_visible) — content mask (1=has notes)\n",
    "ps.mae_mask     # (N_visible,) — all True for already-filtered patches\n",
    "ps.dim          # embedding dimension\n",
    "ps.num_patches  # number of patches\n",
    "\n",
    "vis = ps.visible  # new PatchState with only MAE-visible patches\n",
    "```\n",
    "\n",
    "**In compute_batch_loss (encoder training):**\n",
    "```python\n",
    "# BEFORE: 8 positional return values\n",
    "# loss_dict, z1, z2, non_emptys, pos2, mae_mask2, num_tokens, recon_patches = ...\n",
    "\n",
    "# AFTER:\n",
    "loss_dict, enc_out1, enc_out2, recon_patches = compute_batch_loss(...)\n",
    "non_emptys = (enc_out1.patches.finest.non_empty, enc_out2.patches.finest.non_empty)\n",
    "```\n",
    "\n",
    "**In LightweightMAEDecoder:**\n",
    "```python\n",
    "# BEFORE:\n",
    "# def forward(self, z, pos_full, mae_mask): ...\n",
    "\n",
    "# AFTER:\n",
    "# def forward(self, enc_out: EncoderOutput): ...\n",
    "#   — gets visible embeddings, full positions, and mae_mask all from enc_out\n",
    "```\n",
    "\n",
    "**Future Swin hierarchy (coarsest → finest):**\n",
    "```python\n",
    "# levels[0] = global (like CLS), levels[1] = 4x4, levels[2] = 8x8, levels[3] = 16x16\n",
    "h = enc_out.patches\n",
    "h.coarsest          # global summary\n",
    "h.finest            # finest-resolution patches  \n",
    "h.levels[1]         # intermediate scale\n",
    "h.levels[1].visible # visible patches at that scale\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260b071c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
