{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "436af6f6",
   "metadata": {},
   "source": [
    "# Inspect\n",
    "\n",
    "> (Notebooke only) Interactive exploration of trained encoder and embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75772d19",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Do not try to run this on solveit. The memory requirements will crash the VM.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m",
      "\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#| eval: false\u001b[39;00m",
      "\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m",
      "\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m == os.path.isdir(\u001b[33m'\u001b[39m\u001b[33m/app/data\u001b[39m\u001b[33m'\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33mDo not try to run this on solveit. The memory requirements will crash the VM.\u001b[39m\u001b[33m\"\u001b[39m",
      "",
      "\u001b[31mAssertionError\u001b[39m: Do not try to run this on solveit. The memory requirements will crash the VM."
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "import os\n",
    "assert False == os.path.isdir('/app/data'), \"Do not try to run this on solveit. The memory requirements will crash the VM.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57be90fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from omegaconf import OmegaConf\n",
    "from midi_rae.vit import ViTEncoder\n",
    "from midi_rae.data import PRPairDataset\n",
    "from midi_rae.viz import make_emb_viz\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Interactive visualization (without wandb logging)\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'notebook'\n",
    "from midi_rae.viz import umap_project, pca_project, plot_embeddings_3d, make_emb_viz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a87a2e",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b105de56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "cfg = OmegaConf.load('../configs/config.yaml')\n",
    "device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "print(f'device = {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d03473",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d18b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "val_ds = PRPairDataset(split='val', max_shift_x=cfg.training.max_shift_x, max_shift_y=cfg.training.max_shift_y)\n",
    "val_dl = DataLoader(val_ds, batch_size=cfg.training.batch_size, num_workers=4, drop_last=True)\n",
    "print(f'Loaded {len(val_ds)} validation samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9409e5-4f94-4823-a47f-2316689a19a7",
   "metadata": {},
   "source": [
    "## Inspect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93dca9f-f7db-41d3-86f5-0c18d5699f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "batch = next(iter(val_dl))\n",
    "img1, img2, deltas = batch['img1'].to(device), batch['img2'].to(device), batch['deltas'].to(device)\n",
    "file_idx = batch['file_idx'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fa8fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "# Show a sample image pair\n",
    "idx = 0\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "axes[0].imshow(img1[idx, 0].cpu(), cmap='gray')\n",
    "axes[0].set_title(f'Image 1 (file_idx={file_idx[idx].item()})')\n",
    "axes[1].imshow(img2[idx, 0].cpu(), cmap='gray')\n",
    "axes[1].set_title(f'Image 2 (deltas = {deltas[idx].cpu().int().numpy()})')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ff2335",
   "metadata": {},
   "source": [
    "## Load Encoder from Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16f8890",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "ckpt_path = '../checkpoints/enc_best.pt'  # <-- change as needed\n",
    "\n",
    "model = ViTEncoder(cfg.data.in_channels, (cfg.data.image_size, cfg.data.image_size), \n",
    "                   cfg.model.patch_size, cfg.model.dim, cfg.model.depth, cfg.model.heads).to(device)\n",
    "\n",
    "ckpt = torch.load(ckpt_path, map_location=device, weights_only=False)\n",
    "state_dict = {k.replace('_orig_mod.', ''): v for k, v in ckpt['model_state_dict'].items()}\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "model.eval()\n",
    "print(f'Loaded checkpoint from {ckpt_path}, epoch {ckpt.get(\"epoch\", \"?\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d2fff6",
   "metadata": {},
   "source": [
    "## Run Batch Through Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e09191",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "with torch.no_grad():\n",
    "    z1, pmask1 = model(img1, return_cls_only=False)\n",
    "    z2, pmask2 = model(img2, return_cls_only=False)\n",
    "\n",
    "z1 = z1.reshape(-1, z1.shape[-1])\n",
    "z2 = z2.reshape(-1, z2.shape[-1])\n",
    "num_tokens = z1.shape[0] // len(batch['img1'])\n",
    "\n",
    "print(f'z1: {z1.shape}, z2: {z2.shape}, num_tokens: {num_tokens}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e76cbc6",
   "metadata": {},
   "source": [
    "## Visualize Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56039ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "\n",
    "# Combined embeddings from both views\n",
    "zs = torch.stack([z1, z2], dim=1).reshape(-1, z1.shape[-1])\n",
    "pmask = torch.stack([pmask1, pmask2], dim=1).reshape(-1, z1.shape[-1])\n",
    "file_idx = file_idx.repeat_interleave(zs.shape[0]//file_idx.shape[0])\n",
    "\n",
    "coords = pca_project(zs)\n",
    "fig = plot_embeddings_3d(coords, num_tokens, file_idx=file_idx, title='Embeddings (PCA)')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb500e3e-5ff4-41b5-a346-a8afeb0276cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "figs = make_emb_viz(zs,  num_tokens, epoch=-1, model=None, title='Embeddings', \n",
    "                    max_points=4096, pmask=pmask, file_idx=file_idx, do_umap=False)\n",
    "figs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad4636f-2fbf-4939-a71f-595c37f6296b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
