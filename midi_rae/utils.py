"""utilities"""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/04_utils.ipynb.

# %% auto #0
__all__ = ['save_checkpoint', 'load_checkpoint']

# %% ../nbs/04_utils.ipynb #b96051a7
import os 
import torch

# %% ../nbs/04_utils.ipynb #a164c279
def save_checkpoint(model, optimizer, epoch, val_loss, cfg, save_every=10, n_keep=5, verbose=True, tag=""):
    "Saves new checkpoint, keeps best & the most recent n_keep"
    if not hasattr(save_checkpoint, 'best_val_loss'):
        save_checkpoint.best_val_loss = float('inf')

    os.makedirs('checkpoints', exist_ok=True)
    ckpt = {'epoch': epoch, 'model_state_dict': getattr(model, '_orig_mod', model).state_dict(),
        'optimizer_state_dict': optimizer.state_dict(), 'config': dict(cfg), 'val_loss': val_loss}

    if epoch % save_every == 0:
        if verbose: print(f"Saving checkpoint to checkpoints/{tag}ckpt_epoch{epoch}.pt")
        torch.save(ckpt, f'checkpoints/{tag}ckpt_epoch{epoch}.pt')
    if val_loss < save_checkpoint.best_val_loss:
        torch.save(ckpt, f'checkpoints/{tag}best.pt')
        save_checkpoint.best_val_loss = val_loss

    # delete any checkpoints older than the n_keep-th one
    ckpts = sorted([f for f in os.listdir('checkpoints') if f.startswith(f'{tag}ckpt_epoch')],
               key=lambda x: os.path.getmtime(f'checkpoints/{x}'))
    for old in ckpts[:-n_keep]: os.remove(f'checkpoints/{old}')

# %% ../nbs/04_utils.ipynb #55fb9d50
def load_checkpoint(model, ckpt_path:str, return_all=False, weights_only=False, strict=False):
    "loads a model (and maybe other things) from a checkpoint file"
    print(f">>> Loadeding model checkpoint from {ckpt_path}")
    device = next(model.parameters()).device
    ckpt = torch.load(ckpt_path, map_location=device, weights_only=weights_only)
    state_dict = {k.replace('_orig_mod.', ''): v for k, v in ckpt['model_state_dict'].items()}
    model.load_state_dict(state_dict, strict=strict)
    return (model, state_dict) if return_all else model
