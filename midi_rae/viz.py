"""vizualization routines"""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/05_viz.ipynb.

# %% auto #0
__all__ = ['cpu_umap_project', 'cuml_umap_project', 'umap_project', 'cuml_pca_project', 'cpu_pca_project', 'pca_project',
           'plot_embeddings_3d', 'make_emb_viz', 'expand_patch_mask', 'do_recon_eval', 'patches_to_img',
           'viz_mae_recon']

# %% ../nbs/05_viz.ipynb #b96051a7
import torch
import numpy as np
import wandb
import gc
from torchvision.utils import make_grid

# %% ../nbs/05_viz.ipynb #a164c279
def cpu_umap_project(embeddings, n_components=3, n_neighbors=15, min_dist=0.1, random_state=42):
    "Project embeddings to n_components dimensions via UMAP (on CPU)"
    import umap
    if isinstance(embeddings, torch.Tensor): embeddings = embeddings.detach().cpu().numpy()
    reducer = umap.UMAP(n_components=n_components, n_neighbors=n_neighbors, min_dist=min_dist, random_state=random_state)
    return reducer.fit_transform(embeddings)

# %% ../nbs/05_viz.ipynb #79d07d94
def cuml_umap_project(embeddings, n_components=3, n_neighbors=15, min_dist=0.1, random_state=42):
    "Project embeddings to n_components dimensions via cuML UMAP (GPU)"
    from cuml import UMAP
    import cupy as cp
    if isinstance(embeddings, torch.Tensor): embeddings = cp.from_dlpack(embeddings.detach())
    reducer = UMAP(n_components=n_components, n_neighbors=n_neighbors, min_dist=min_dist, random_state=random_state)
    coords = reducer.fit_transform(embeddings)
    del reducer
    return cp.asnumpy(coords)  # back to numpy for plotly

# %% ../nbs/05_viz.ipynb #b8cf6f27
def umap_project(embeddings, **kwargs): 
    "Calls one of two preceding UMAP routines based on device availability."
    if embeddings.is_cuda:
        try: return cuml_umap_project(embeddings, **kwargs)
        except torch.cuda.OutOfMemoryError:
            torch.cuda.empty_cache()
            return cpu_umap_project(embeddings, **kwargs)
    return cpu_umap_project(embeddings, **kwargs)

# %% ../nbs/05_viz.ipynb #a4fef620
def cuml_pca_project(embeddings, n_components=3):
    "Project embeddings to n_components dimensions via cuML PCA (GPU)"
    from cuml import PCA
    import cupy as cp
    if isinstance(embeddings, torch.Tensor): embeddings = cp.from_dlpack(embeddings.detach())
    coords = PCA(n_components=n_components).fit_transform(embeddings)
    return cp.asnumpy(coords)

# %% ../nbs/05_viz.ipynb #047d5a1d
def cpu_pca_project(embeddings, n_components=3):
    "Project embeddings to n_components dimensions via sklearn PCA (CPU)"
    from sklearn.decomposition import PCA
    if isinstance(embeddings, torch.Tensor): embeddings = embeddings.detach().cpu().numpy()
    return PCA(n_components=n_components).fit_transform(embeddings)

# %% ../nbs/05_viz.ipynb #cf52f98b
def pca_project(embeddings, **kwargs):
    "Calls GPU or CPU PCA based on availability"
    if embeddings.is_cuda:
        try: return cuml_pca_project(embeddings, **kwargs)
        except: return cpu_pca_project(embeddings, **kwargs)
    return cpu_pca_project(embeddings, **kwargs)

# %% ../nbs/05_viz.ipynb #1c5d9cc8
@torch.no_grad()
def plot_embeddings_3d(coords, color_by='pairs', file_idx=None, deltas=None, title='Embeddings', debug=False):
    "3D scatter plot of embeddings. color_by: 'none', 'file', or 'pair'"
    import plotly.graph_objects as go
    n = len(coords)
    if debug: print(" plot_embeddings_3d: n =",n)
    
    if color_by == 'none':     colors = ['blue'] * n
    elif color_by == 'file':   colors = file_idx.tolist() if file_idx is not None else ['blue'] * n
    elif color_by == 'pairs':
        n_pairs = n // 2
        pair_colors = [f'rgb({np.random.randint(0,256)},{np.random.randint(0,256)},{np.random.randint(0,256)})' for _ in range(n_pairs)]
        colors = [pair_colors[i % n_pairs] for i in range(n)]  # pairs separated by num_tokens 
    else: raise ValueError(f"Unknown color_by: {color_by}")

    hover_text = [f"file_id: {int(fid)}, deltas: {ds.cpu().numpy()}" for fid, ds in zip(file_idx,deltas)] if (file_idx is not None) and (deltas is not None) else None
    if color_by == 'pairs':
        hover_text = [f"pair {i%n_pairs}" for i in range(n)] if hover_text is None else [f"{s}, pair {i%n_pairs}" for i, s in enumerate(hover_text)]

    
    fig = go.Figure(data=[go.Scatter3d(
        x=coords[:,0], y=coords[:,1], z=coords[:,2],
        mode='markers', 
        marker=dict(size=4, color=colors, colorscale='Viridis' if color_by != 'pairs' else None, opacity=0.8),
        hovertext=hover_text, hoverinfo='x+y+z+text' if hover_text else 'x+y+z'
    )])
    title = title + f', n={n}'
    fig.update_layout(title=title, margin=dict(l=0, r=0, b=0, t=30))
    return fig

# %% ../nbs/05_viz.ipynb #f1feb8ca
@torch.no_grad()
def _make_emb_viz(zs, epoch=-1, title='Embeddings', do_umap=True, file_idx=None, deltas=None):
    "visualize embeddings, projected"
    umap_fig = None
    if do_umap:
        coords = umap_project(zs)
        umap_fig = plot_embeddings_3d(coords, title=title+f' (UMAP), epoch {epoch}', file_idx=file_idx, deltas=deltas)
    if torch.cuda.is_available(): torch.cuda.synchronize() # cleanup before PCA or else you get CUDA errors
    gc.collect()
    coords = pca_project(zs)
    pca_fig = plot_embeddings_3d(coords, title=title+f' (PCA), epoch {epoch}', file_idx=file_idx, deltas=deltas)
    if wandb.run is not None: 
        if do_umap:
            wandb.log({f"{title} UMAP": wandb.Html(umap_fig.to_html()), f"{title} PCA": wandb.Html(pca_fig.to_html())})
        else:
            wandb.log({f"{title} PCA": wandb.Html(pca_fig.to_html())})
    if torch.cuda.is_available(): torch.cuda.synchronize() # cleanup again
    gc.collect()
    return pca_fig, umap_fig

# %% ../nbs/05_viz.ipynb #b618d453
def _subsample(data, indices, deltas, max_points, debug=False):
    "Subsample data and indices together, in pairs"
    perm1 = torch.randperm(len(data)//2)[:max_points//2]
    perm2 = perm1 + len(data)//2
    perm = torch.cat([perm1,perm2])
    return data[perm], indices[perm], deltas[perm]

# %% ../nbs/05_viz.ipynb #a64048f1
@torch.no_grad()
def make_emb_viz(enc_outs, epoch=-1, encoder=None, batch=None, title='Embeddings', max_points=5000, do_umap=True, debug=False):
    "this is the main viz routine, showing different groups of embeddings"
    device = enc_outs[0].patches[0].emb.device
    if encoder is not None: encoder.to('cpu')
    torch.cuda.empty_cache()

    num_patch_tokens = enc_outs[0].patches[-1].num_patches

    file_idx, deltas = None, None
    if batch is not None:
        file_idx = batch['file_idx'].repeat(2).repeat_interleave(num_patch_tokens).to(device)
        deltas = batch['deltas'].repeat(2, 1).repeat_interleave(num_patch_tokens, dim=0).to(device)

    # CLS tokens aka coarsest level
    cls_tokens = torch.cat((enc_outs[0].patches[0].emb, enc_outs[1].patches[0].emb), dim=0).squeeze(1)
    cls_file_idx = batch['file_idx'].repeat(2).to(device) if batch is not None else None
    cls_deltas = batch['deltas'].repeat(2, 1).to(device) if batch is not None else None
    cls_pca_fig, cls_umap_fig = _make_emb_viz(cls_tokens, epoch=epoch, title='CLS Tokens '+title, file_idx=cls_file_idx, deltas=cls_deltas, do_umap=do_umap)

    # Patches (non-CLS) aka finest level — already CLS-stripped via patches[-1]
    dim = enc_outs[0].patches[-1].dim
    patches = torch.cat((enc_outs[0].patches[-1].emb, enc_outs[1].patches[-1].emb), dim=0).reshape(-1, dim)
    non_empty = (enc_outs[0].patches[-1].non_empty.bool() & enc_outs[1].patches[-1].non_empty.bool())
    valid = non_empty.flatten().repeat(2)

    # Non-empty patches
    valid_patches, valid_file_idx, valid_deltas = patches[valid], file_idx[valid], deltas[valid]
    rnd_patches, rnd_file_idx, rnd_deltas = _subsample(valid_patches, valid_file_idx, valid_deltas, max_points)
    patch_pca_fig, patch_umap_fig = _make_emb_viz(rnd_patches, epoch=epoch, title='RND Patches '+title, file_idx=rnd_file_idx, deltas=rnd_deltas, do_umap=do_umap)

    # plot when both patches are empty 
    ne1 = enc_outs[0].patches[-1].non_empty.flatten().repeat(2).bool()
    ne2 = enc_outs[1].patches[-1].non_empty.flatten().repeat(2).bool()
    both_empty = ~ne1 & ~ne2
    empty_pca_fig = None
    if both_empty.any():
        empty_patches, empty_file_idx, empty_deltas = patches[both_empty], file_idx[both_empty], deltas[both_empty]
        if debug: print("emtpy: patches[~both_empty].norm(dim=-1).mean() = ",patches[~both_empty].norm(dim=-1).mean())
        rnd_empty, rnd_empty_idx, rnd_empty_deltas = _subsample(empty_patches, empty_file_idx, empty_deltas, max_points)
        empty_pca_fig = _make_emb_viz(rnd_empty, epoch=epoch, title='RND Empty Patches '+title, do_umap=False, file_idx=rnd_empty_idx, deltas=rnd_empty_deltas)
    
    if encoder is not None: encoder.to(device)
    figs = {'cls_pca_fig':cls_pca_fig, 'cls_umap_fig':cls_umap_fig, 'patch_pca_fig':patch_pca_fig, 'patch_umap_fig':patch_umap_fig, 'empty_pca_fig': empty_pca_fig}
    return figs

# %% ../nbs/05_viz.ipynb #f450ea65-c24c-4675-894d-792ee4a9b986
def expand_patch_mask(mae_mask, grid_h, grid_w, patch_size):
    """Expand patch-level mask (N,) to pixel-level mask (H, W)"""
    return mae_mask.bool().reshape(grid_h, grid_w).repeat_interleave(patch_size, 0).repeat_interleave(patch_size, 1)

# %% ../nbs/05_viz.ipynb #6be20056-1385-46cc-972f-ab1207bce9a6
def do_recon_eval(recon, real, mae_mask=None, patch_size=16, eps=1e-8): 
    "Evaluate recon accuracy, optionally only on masked patches"
    if mae_mask is not None: 
        B, C, H, W = real.shape
        grid_h, grid_w = H//patch_size, W//patch_size
        masked = ~expand_patch_mask(mae_mask, grid_h, grid_w, patch_size)
        recon, real = recon[:, :, masked], real[:, :, masked] 
    TP = (recon * real).sum()
    FP = (recon * (1 - real)).sum()
    FN = ((1 - recon) * real).sum()
    TN = ((1 - recon) * (1 - real)).sum()
    precision = TP / (TP + FP + eps) 
    recall = TP / (TP + FN + eps) 
    specificity = TN / (TN + FP + eps) 
    f1 = 2 * precision * recall / (precision + recall + eps) 
    evals = {'precision': precision, 'recall': recall, 'specificity': specificity, 'f1': f1}
    if wandb.run is not None: wandb.log(evals) 
    return evals 

# %% ../nbs/05_viz.ipynb #1aaee236-717b-408c-8252-2e0048f63211
def patches_to_img(recon_patches, img_real, patch_size=16, mae_mask=None):
    "Convert image patches to full image. Copy over real patches where appropriate."
    B, C, H, W = img_real.shape
    grid_h, grid_w = H//patch_size, W//patch_size
    n_patches = grid_h * grid_w
    if recon_patches.shape[1] > n_patches: recon_patches = recon_patches[:, -n_patches:]  # strip cls if present
    img_recon = recon_patches.reshape(B, grid_h, grid_w, patch_size, patch_size).permute(0, 1, 3, 2, 4)
    img_recon = img_recon.reshape(B, H, W).unsqueeze(1)
    img_recon = torch.sigmoid(img_recon)
    img_recon = (img_recon > 0.25).float()
    if mae_mask is not None:
        vis_2d = expand_patch_mask(mae_mask, grid_h, grid_w, patch_size)
        img_recon[:, :, vis_2d] = img_real[:, :, vis_2d]
    return img_recon 

# %% ../nbs/05_viz.ipynb #86455273-d2fa-4a97-a6a7-0a71a0a7798f
@torch.no_grad()
def viz_mae_recon(recon, img_real, enc_out=None, epoch=-1, patch_size=16, debug=False):
    """Show how our LightweightMAEDecoder is doing (during encoder training)"""
    mae_mask = None
    if enc_out is not None:
        mae_mask = enc_out.mae_mask
        if mae_mask.ndim == 2: mae_mask = mae_mask[0]   # Swin: (B,N) → take first sample
        elif mae_mask.shape[0] % 2 != 0: mae_mask = mae_mask[1:]  # ViT: strip CLS from (N,)
    recon, img_real = recon.cpu(), img_real.cpu()
    if mae_mask is not None: mae_mask = mae_mask.cpu()
    if debug: print(f"mae_mask: shape={mae_mask.shape}, pct_visible={mae_mask.float().mean():.3f}")

    img_recon_noreplace = None
    if recon.shape != img_real.shape:
        img_recon = patches_to_img(recon, img_real, patch_size=patch_size, mae_mask=mae_mask)
        img_recon_noreplace = patches_to_img(recon, img_real, patch_size=patch_size, mae_mask=None)
    else:
        img_recon = (recon > 0.25).float()
    evals = do_recon_eval(img_recon, img_real, mae_mask=mae_mask, patch_size=patch_size)
    grid_recon = make_grid(img_recon[:64], nrow=8, normalize=True)
    grid_real  = make_grid(img_real[:64], nrow=8, normalize=True)
    if wandb.run is not None:
        wandb_dict = {'real': wandb.Image(grid_real, caption=f"Epoch {epoch}"),
                      'recon': wandb.Image(grid_recon, caption=f"Epoch {epoch}"), 'epoch': epoch}
        if img_recon_noreplace is not None:
            grid_raw = make_grid(img_recon_noreplace[:64], nrow=8, normalize=True)
            wandb_dict = wandb_dict | {'raw': wandb.Image(grid_raw, caption=f"Epoch {epoch}")}
        wandb.log(wandb_dict)
    return grid_recon, grid_real, evals
