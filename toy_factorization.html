<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.27">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="Can a simple encoder learn “soft-separable” pitch vs time directions in latent space? An alternative to explicit factorization.">

<title>Toy “Soft” Factorization Experiment – midi-rae</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js" integrity="sha384-ZvpUoO/+PpLXR1lu4jmpXWu80pZlYUAfxl5NsBMWOEPSjUn/6Z/hRTt8+pR6L4N2" crossorigin="anonymous"></script><script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-ed96de9b727972fe78a7b5d16c58bf87.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-baedc78cbf92349237790bf011c153e8.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdn.jsdelivr.net/npm/requirejs@2.3.6/require.min.js" integrity="sha384-c9c+LnTbwQ3aujuU7ULEPVvgLs+Fn6fJUvIGTsuu1ZcCf11fiEubah0ttpca4ntM sha384-6V1/AdqZRWk1KAlWbKBlGhN7VG4iE/yAZcO6NZPMF8od0vukrvr0tg4qY6NSrItx" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@*/dist/embed-amd.js" crossorigin="anonymous"></script>


<link rel="stylesheet" href="styles.css">
<meta property="og:title" content="Toy “Soft” Factorization Experiment – midi-rae">
<meta property="og:description" content="Can a simple encoder learn “soft-separable” pitch vs time directions in latent space? An alternative to explicit factorization.">
<meta property="og:image" content="https://drscotthawley.github.io/midi-rae/11_toy_factorization_files/figure-html/3d8a2688-3-94f70fc1-e70e-454a-a41b-ff4e7158a2a5.png">
<meta property="og:site_name" content="midi-rae">
<meta name="twitter:title" content="Toy “Soft” Factorization Experiment – midi-rae">
<meta name="twitter:description" content="Can a simple encoder learn “soft-separable” pitch vs time directions in latent space? An alternative to explicit factorization.">
<meta name="twitter:image" content="https://drscotthawley.github.io/midi-rae/11_toy_factorization_files/figure-html/3d8a2688-3-94f70fc1-e70e-454a-a41b-ff4e7158a2a5.png">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-sidebar floating nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">midi-rae</span>
    </a>
  </div>
        <div class="quarto-navbar-tools tools-end">
</div>
          <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./toy_factorization.html">Toy “Soft” Factorization Experiment</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">midi-rae</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./core.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">core</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">data</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./vit.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ViT</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./losses.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">losses</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./utils.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">utils</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./viz.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">viz</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./train_enc.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">train_enc</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./inspect.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Inspect</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preencode.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Pre-encode</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./train_dec.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Train Decoder</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./swin.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">swin</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./toy_factorization.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Toy “Soft” Factorization Experiment</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#tldr" id="toc-tldr" class="nav-link active" data-scroll-target="#tldr">TL;DR</a></li>
  <li><a href="#motivation" id="toc-motivation" class="nav-link" data-scroll-target="#motivation">Motivation</a>
  <ul class="collapse">
  <li><a href="#why-factorize-pitch-and-time" id="toc-why-factorize-pitch-and-time" class="nav-link" data-scroll-target="#why-factorize-pitch-and-time">Why factorize pitch and time?</a></li>
  <li><a href="#why-soft-factorization" id="toc-why-soft-factorization" class="nav-link" data-scroll-target="#why-soft-factorization">Why soft factorization?</a></li>
  <li><a href="#why-blobs" id="toc-why-blobs" class="nav-link" data-scroll-target="#why-blobs">Why blobs?</a></li>
  </ul></li>
  <li><a href="#the-larger-context" id="toc-the-larger-context" class="nav-link" data-scroll-target="#the-larger-context">The Larger Context</a>
  <ul class="collapse">
  <li><a href="#why-a-toy-model" id="toc-why-a-toy-model" class="nav-link" data-scroll-target="#why-a-toy-model">Why a toy model?</a></li>
  </ul></li>
  <li><a href="#data-random-blob-patches-augmentations" id="toc-data-random-blob-patches-augmentations" class="nav-link" data-scroll-target="#data-random-blob-patches-augmentations">Data: Random blob patches + augmentations</a></li>
  <li><a href="#encoder-tiny-convnet-latent-vector" id="toc-encoder-tiny-convnet-latent-vector" class="nav-link" data-scroll-target="#encoder-tiny-convnet-latent-vector">Encoder: tiny ConvNet → latent vector</a></li>
  <li><a href="#loss-cosine-factorization-objective" id="toc-loss-cosine-factorization-objective" class="nav-link" data-scroll-target="#loss-cosine-factorization-objective">Loss: cosine factorization objective</a></li>
  <li><a href="#lejepa-too" id="toc-lejepa-too" class="nav-link" data-scroll-target="#lejepa-too">LeJEPA too?</a></li>
  <li><a href="#training-loop" id="toc-training-loop" class="nav-link" data-scroll-target="#training-loop">Training loop</a></li>
  <li><a href="#loss-curve" id="toc-loss-curve" class="nav-link" data-scroll-target="#loss-curve">Loss curve</a></li>
  <li><a href="#visualization-pitch-time-difference-vectors-separate-cleanly" id="toc-visualization-pitch-time-difference-vectors-separate-cleanly" class="nav-link" data-scroll-target="#visualization-pitch-time-difference-vectors-separate-cleanly">Visualization: pitch &amp; time difference vectors separate cleanly</a></li>
  <li><a href="#results-summary" id="toc-results-summary" class="nav-link" data-scroll-target="#results-summary">Results summary</a>
  <ul class="collapse">
  <li><a href="#probing-the-1-asymmetry" id="toc-probing-the-1-asymmetry" class="nav-link" data-scroll-target="#probing-the-1-asymmetry">Probing the ±1 asymmetry</a></li>
  <li><a href="#svd-on-shift-grids" id="toc-svd-on-shift-grids" class="nav-link" data-scroll-target="#svd-on-shift-grids">SVD on shift grids</a></li>
  </ul></li>
  <li><a href="#deeper-analysis-kernel-pca-and-svd" id="toc-deeper-analysis-kernel-pca-and-svd" class="nav-link" data-scroll-target="#deeper-analysis-kernel-pca-and-svd">Deeper analysis: Kernel PCA and SVD</a></li>
  <li><a href="#does-umap-show-us-anything" id="toc-does-umap-show-us-anything" class="nav-link" data-scroll-target="#does-umap-show-us-anything">Does UMAP Show Us Anything?</a></li>
  <li><a href="#discussion" id="toc-discussion" class="nav-link" data-scroll-target="#discussion">Discussion</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/drscotthawley/midi-rae/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div><div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="toy_factorization.html.md"><i class="bi bi-file-code"></i>CommonMark</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Toy “Soft” Factorization Experiment</h1>
</div>

<div>
  <div class="description">
    Can a simple encoder learn “soft-separable” pitch vs time directions in latent space? An alternative to explicit factorization.
  </div>
</div>


<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->
<section id="tldr" class="level2">
<h2 class="anchored" data-anchor-id="tldr">TL;DR</h2>
<p>We use our explicit data augmentation of translations and pitch and time and feed those as labels into a loss function to try and encode those operations geometrically. Add this loss function to an encoder and see if it achieves a <strong>soft factorization</strong> of pitch and time:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> factorization_loss(z_anchor, z_crop1, z_crop2, targets):</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    d1 <span class="op">=</span> z_crop1 <span class="op">-</span> z_anchor</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>    d2 <span class="op">=</span> z_crop2 <span class="op">-</span> z_anchor</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    cos <span class="op">=</span> F.cosine_similarity(d1, d2, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> ((cos <span class="op">-</span> targets) <span class="op">**</span> <span class="dv">2</span>).mean()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>where <code>targets</code> are +1 (same-type, same-sign), −1 (same-type, opposite-sign), or 0 (cross-type):</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="11_toy_factorization_files/figure-html/3d8a2688-3-94f70fc1-e70e-454a-a41b-ff4e7158a2a5.png" class="img-fluid figure-img"></p>
<figcaption>image.png</figcaption>
</figure>
</div>
<p>(We do not specify these directions. We simply enforce parallel, anti-parallel, or orthogonal, and let the system evolve on its own.)</p>
<p><strong>Spoiler: it works.</strong> Since this toy model succeeds, we will have confidence to move on to applying it to the full problem with real MIDI data.</p>
</section>
<section id="motivation" class="level2">
<h2 class="anchored" data-anchor-id="motivation">Motivation</h2>
<section id="why-factorize-pitch-and-time" class="level3">
<h3 class="anchored" data-anchor-id="why-factorize-pitch-and-time">Why factorize pitch and time?</h3>
<p>Musical motifs exhibit repeated melodic patterns (pitch) and repeated rhythmic patterns (time) that together explain much of the variety within a song. This suggests a natural decomposition of musical representations into a <strong>pitch vocabulary</strong> and a <strong>rhythm vocabulary</strong>, where a given motif can be approximated as an interaction (outer product) of pitch and time components. Factored representations are also connected to compositional algebraic properties — the <strong>GloVe</strong> word vectors (Pennington et al., 2014) demonstrated that vector arithmetic relationships (e.g., <em>king − man + woman ≈ queen</em>) arose from GloVe’s explicitly factorized construction of word co-occurrence matrices.</p>
</section>
<section id="why-soft-factorization" class="level3">
<h3 class="anchored" data-anchor-id="why-soft-factorization">Why soft factorization?</h3>
<p>Prior work in symbolic music analysis has explored both fully factored and fully combined representations. Notably, <strong>MelodyGLM</strong> (Wu et al., 2023) compared pitch n-grams, rhythm n-grams, and combined n-grams for melody generation. Their ablation study showed that using all three together worked best, but that the <em>combined</em> (non-factored) n-grams carried meaningful information lost by independent factorization. Similarly, <strong>Music SketchNet</strong> (Chen et al., 2020) and <strong>PiRhDy</strong> (Liang et al., 2020) construct factored representations by design, which limits the model’s ability to capture pitch–rhythm interactions.</p>
<p>This motivates a <strong>middle path</strong>: rather than forcing factorization by construction (hard factorization) or hoping to discover it post-hoc (e.g., GANSpace), we use a <strong>soft factorization</strong> via the loss function. The cosine-similarity loss encourages orthogonality between pitch and time directions in latent space, while still allowing the model freedom to represent non-factored structure. This approach is inspired by the idea—articulated in Albinet (2026)—that competing soft constraints in an objective can give rise to discrete eigenstructure at equilibrium, analogous to how kernel PCA discovers structure through balanced forces rather than hard architectural choices.</p>
<p>Recent theoretical work lends further support to this direction. <strong>Shai et al.&nbsp;(2026)</strong> show that transformers trained via next-token prediction naturally learn <strong>factored representations</strong> in orthogonal subspaces when the underlying factors are conditionally independent — and exhibit an inductive bias toward factoring even when strict independence is violated. This suggests that factored structure is not merely a convenient assumption but something models actively prefer, and that nudging them toward it via a soft loss aligns with their natural learning dynamics.</p>
</section>
<section id="why-blobs" class="level3">
<h3 class="anchored" data-anchor-id="why-blobs">Why blobs?</h3>
<p>This toy experiment uses random binary blob images as a stand-in for MIDI piano-roll data. Vertical shifts simulate <strong>pitch transposition</strong> and horizontal shifts simulate <strong>time shifting</strong>. These shifts are exact, continuous, and independently controllable—making this domain particularly well-suited for testing whether soft geometric constraints can induce factored latent structure. The real target application is learning factored representations of musical motifs, where the training signal would come from a JEPA-style self-supervised objective augmented with this orthogonality loss.</p>
</section>
</section>
<section id="the-larger-context" class="level2">
<h2 class="anchored" data-anchor-id="the-larger-context">The Larger Context</h2>
<p>I’m building a Representation Autoencoder (RAE, Zheng et al., 2025) for MIDI music based on piano roll representations. I had the idea that some kind of factorization in pitch and time would be useful, but actually prescribing it by construction would probably be detrimental (as the MelodyGLM paper noted). And I love trying to do geometrical operations in latent space, e.g., Operational Latent Spaces (OpLaS, Hawley &amp; Tackett, 2024).</p>
<p>So, after reading Franck’s series on SVD (Abinet, 2026), which includes contact with contrastive losses and soft objectives. This seemed like a natural thing thing to try!</p>
<section id="why-a-toy-model" class="level3">
<h3 class="anchored" data-anchor-id="why-a-toy-model">Why a toy model?</h3>
<p>I generally like to create toy models when I do anything new because they’re interpretable and you can iterate quickly. If I couldn’t even get the thing to work on this simple system with a small latent space and fake piano rolls, then what hope would I have for doing it in the larger context with the full code and the real data?</p>
<div id="b1" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch, torch.nn <span class="im">as</span> nn, torch.nn.functional <span class="im">as</span> F</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt, numpy <span class="im">as</span> np</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm.auto <span class="im">import</span> trange, tqdm</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>: <span class="im">import</span> wandb<span class="op">;</span> HAS_WANDB <span class="op">=</span> <span class="va">True</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> <span class="pp">ImportError</span>: HAS_WANDB <span class="op">=</span> <span class="va">False</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"HAS_WANDB ="</span>,HAS_WANDB)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> <span class="st">'cuda'</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">'mps'</span> <span class="cf">if</span> torch.backends.mps.is_available() <span class="cf">else</span> <span class="st">'cpu'</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Using </span><span class="sc">{</span>device<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>HAS_WANDB = True
Using cuda</code></pre>
</div>
</div>
</section>
</section>
<section id="data-random-blob-patches-augmentations" class="level2">
<h2 class="anchored" data-anchor-id="data-random-blob-patches-augmentations">Data: Random blob patches + augmentations</h2>
<div id="3fd3dc01-874c-4b1c-bd78-10b57b4bfc48" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> make_blob(sz<span class="op">=</span><span class="dv">16</span>, n_blobs<span class="op">=</span><span class="dv">3</span>):</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Generate a random binary blob image (1, sz, sz)."""</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> torch.zeros(<span class="dv">1</span>, sz, sz)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(n_blobs):</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>        r, c <span class="op">=</span> torch.randint(<span class="dv">0</span>, sz<span class="op">-</span><span class="dv">3</span>, (<span class="dv">2</span>,))</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>        h, w <span class="op">=</span> torch.randint(<span class="dv">1</span>, <span class="dv">4</span>, (<span class="dv">2</span>,))</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>        img[<span class="dv">0</span>, r:r<span class="op">+</span>h, c:c<span class="op">+</span>w] <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> torch.rand(<span class="dv">1</span>) <span class="op">&gt;</span> <span class="fl">0.5</span>: img <span class="op">=</span> torch.flip(img, [<span class="dv">1</span>])</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> torch.rand(<span class="dv">1</span>) <span class="op">&gt;</span> <span class="fl">0.5</span>: img <span class="op">=</span> torch.flip(img, [<span class="dv">2</span>])</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> img</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="43fdf5a8-9058-417d-b144-3eebfdcfe626" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> shift_no_wrap(x, shifts, dims):</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Drop-in replacement for torch.roll with zero-fill instead of wrap."""</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> shifts <span class="op">==</span> <span class="dv">0</span>: <span class="cf">return</span> x</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    out <span class="op">=</span> torch.roll(x, shifts<span class="op">=</span>shifts, dims<span class="op">=</span>dims)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> <span class="bu">abs</span>(shifts)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> shifts <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>        out.narrow(dims, <span class="dv">0</span>, n).zero_()</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>        out.narrow(dims, out.size(dims)<span class="op">-</span>n, n).zero_()</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> out</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="22da6d3a-30ad-4c6e-a872-61d500811bfe" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Quick visual test</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> make_blob()</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">5</span>, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> row <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>):</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    axes[row, <span class="dv">0</span>].imshow(img[<span class="dv">0</span>], cmap<span class="op">=</span><span class="st">'gray'</span>, vmin<span class="op">=</span><span class="dv">0</span>, vmax<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    axes[row, <span class="dv">0</span>].set_title(<span class="st">'Original'</span>)</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, s <span class="kw">in</span> <span class="bu">enumerate</span>([<span class="op">-</span><span class="dv">4</span>, <span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">4</span>]):</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">0</span>, i<span class="op">+</span><span class="dv">1</span>].imshow(shift_no_wrap(img, s, <span class="dv">1</span>)[<span class="dv">0</span>], cmap<span class="op">=</span><span class="st">'gray'</span>, vmin<span class="op">=</span><span class="dv">0</span>, vmax<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">0</span>, i<span class="op">+</span><span class="dv">1</span>].set_title(<span class="ss">f'dy=</span><span class="sc">{</span>s<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">1</span>, i<span class="op">+</span><span class="dv">1</span>].imshow(shift_no_wrap(img, s, <span class="dv">2</span>)[<span class="dv">0</span>], cmap<span class="op">=</span><span class="st">'gray'</span>, vmin<span class="op">=</span><span class="dv">0</span>, vmax<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">1</span>, i<span class="op">+</span><span class="dv">1</span>].set_title(<span class="ss">f'dx=</span><span class="sc">{</span>s<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ax <span class="kw">in</span> axes.flat: ax.set_xticks([])<span class="op">;</span> ax.set_yticks([])</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].set_ylabel(<span class="st">'Vertical'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>, <span class="dv">0</span>].set_ylabel(<span class="st">'Horizontal'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">'shift_no_wrap: zero-padded shifts'</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()<span class="op">;</span> plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11_toy_factorization_files/figure-html/cell-5-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="b16503ac-8e11-4327-883c-ba4bc18c0079" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> BlobShiftDataset(torch.utils.data.Dataset):</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, epoch_size<span class="op">=</span><span class="dv">8192</span>, sz<span class="op">=</span><span class="dv">16</span>, max_shift<span class="op">=</span><span class="dv">4</span>):</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.epoch_size <span class="op">=</span> epoch_size</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.sz <span class="op">=</span> sz</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.max_shift <span class="op">=</span> max_shift</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>): <span class="cf">return</span> <span class="va">self</span>.epoch_size</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, idx):</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>        sz, ms <span class="op">=</span> <span class="va">self</span>.sz, <span class="va">self</span>.max_shift</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>            img <span class="op">=</span> make_blob(sz)</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>            scheme <span class="op">=</span> torch.randint(<span class="dv">0</span>, <span class="dv">3</span>, (<span class="dv">1</span>,)).item()</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>            s1 <span class="op">=</span> torch.randint(<span class="dv">1</span>, ms<span class="op">+</span><span class="dv">1</span>, (<span class="dv">1</span>,)).item()</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>            s2 <span class="op">=</span> torch.randint(<span class="dv">1</span>, ms<span class="op">+</span><span class="dv">1</span>, (<span class="dv">1</span>,)).item()</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>            sign1 <span class="op">=</span> <span class="dv">1</span> <span class="cf">if</span> torch.rand(<span class="dv">1</span>) <span class="op">&gt;</span> <span class="fl">0.5</span> <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>            sign2 <span class="op">=</span> <span class="dv">1</span> <span class="cf">if</span> torch.rand(<span class="dv">1</span>) <span class="op">&gt;</span> <span class="fl">0.5</span> <span class="cf">else</span> <span class="op">-</span><span class="dv">1</span></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> scheme <span class="op">==</span> <span class="dv">0</span>:    dy1, dx1, dy2, dx2 <span class="op">=</span> sign1<span class="op">*</span>s1, <span class="dv">0</span>, sign2<span class="op">*</span>s2, <span class="dv">0</span></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>            <span class="cf">elif</span> scheme <span class="op">==</span> <span class="dv">1</span>:  dy1, dx1, dy2, dx2 <span class="op">=</span> <span class="dv">0</span>, sign1<span class="op">*</span>s1, <span class="dv">0</span>, sign2<span class="op">*</span>s2</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:              dy1, dx1, dy2, dx2 <span class="op">=</span> sign1<span class="op">*</span>s1, <span class="dv">0</span>, <span class="dv">0</span>, sign2<span class="op">*</span>s2</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>            c1 <span class="op">=</span> shift_no_wrap(shift_no_wrap(img, shifts<span class="op">=</span>dy1, dims<span class="op">=</span><span class="dv">1</span>), shifts<span class="op">=</span>dx1, dims<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>            c2 <span class="op">=</span> shift_no_wrap(shift_no_wrap(img, shifts<span class="op">=</span>dy2, dims<span class="op">=</span><span class="dv">1</span>), shifts<span class="op">=</span>dx2, dims<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="kw">not</span> torch.equal(c1, c2): <span class="cf">break</span></span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>        target <span class="op">=</span> <span class="bu">float</span>(np.sign(sign1 <span class="op">*</span> sign2)) <span class="cf">if</span> scheme <span class="op">&lt;</span> <span class="dv">2</span> <span class="cf">else</span> <span class="fl">0.0</span></span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> img, c1, c2, torch.tensor(target), torch.tensor(scheme), (dy1, dx1), (dy2, dx2)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>Viz test of that:</p>
<div id="9fa9bb76-6433-4d88-a540-9bb711182b03" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> show_triplets(anchors, crop1s, crop2s, targets, schemes, deltas1, deltas2, n_rows<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Visualize triplets with colored borders and delta labels.</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Colors: blue=pitch/pitch, green=time/time, red=pitch+time.</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    <span class="im">from</span> matplotlib.patches <span class="im">import</span> Patch</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    scheme_colors <span class="op">=</span> {<span class="dv">0</span>: <span class="st">'#4488ff'</span>, <span class="dv">1</span>: <span class="st">'#33bb55'</span>, <span class="dv">2</span>: <span class="st">'#dd3333'</span>}</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> n_rows <span class="kw">is</span> <span class="va">None</span>: n_rows <span class="op">=</span> <span class="bu">len</span>(anchors)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>    n_rows <span class="op">=</span> <span class="bu">min</span>(n_rows, <span class="bu">len</span>(anchors))</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>    fig, axes <span class="op">=</span> plt.subplots(n_rows, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">8</span>, n_rows <span class="op">*</span> <span class="fl">1.5</span>))</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> n_rows <span class="op">==</span> <span class="dv">1</span>: axes <span class="op">=</span> axes[<span class="va">None</span>]  <span class="co"># ensure 2D</span></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> trange(n_rows):</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>        color <span class="op">=</span> scheme_colors[schemes[i].item()]</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j, (img, title) <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="bu">zip</span>(</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>                [anchors[i], crop1s[i], crop2s[i]], [<span class="st">"Anchor"</span>, <span class="st">"Crop 1"</span>, <span class="st">"Crop 2"</span>])):</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>            axes[i, j].imshow(img[<span class="dv">0</span>], cmap<span class="op">=</span><span class="st">"gray"</span>, vmin<span class="op">=</span><span class="dv">0</span>, vmax<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>            axes[i, j].set_title(title <span class="cf">if</span> i <span class="op">==</span> <span class="dv">0</span> <span class="cf">else</span> <span class="st">""</span>, fontsize<span class="op">=</span><span class="dv">24</span>)</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>            axes[i, j].set_xticks([])<span class="op">;</span> axes[i, j].set_yticks([])</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> spine <span class="kw">in</span> axes[i, j].spines.values():</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>                spine.set_color(color)<span class="op">;</span> spine.set_linewidth(<span class="fl">2.5</span>)</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>        dy1, dx1 <span class="op">=</span> deltas1[<span class="dv">0</span>][i].item(), deltas1[<span class="dv">1</span>][i].item()</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>        dy2, dx2 <span class="op">=</span> deltas2[<span class="dv">0</span>][i].item(), deltas2[<span class="dv">1</span>][i].item()</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>        axes[i, <span class="dv">1</span>].set_ylabel(<span class="ss">f"Δ(</span><span class="sc">{</span>dy1<span class="sc">:+d}</span><span class="ss">,</span><span class="sc">{</span>dx1<span class="sc">:+d}</span><span class="ss">)"</span>, fontsize<span class="op">=</span><span class="dv">15</span>, color<span class="op">=</span>color, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>        axes[i, <span class="dv">2</span>].set_ylabel(<span class="ss">f"Δ(</span><span class="sc">{</span>dy2<span class="sc">:+d}</span><span class="ss">,</span><span class="sc">{</span>dx2<span class="sc">:+d}</span><span class="ss">)"</span>, fontsize<span class="op">=</span><span class="dv">15</span>, color<span class="op">=</span>color, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>    legend_items <span class="op">=</span> [</span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>        Patch(facecolor<span class="op">=</span><span class="st">'white'</span>, edgecolor<span class="op">=</span><span class="st">'#4488ff'</span>, linewidth<span class="op">=</span><span class="dv">3</span>, label<span class="op">=</span><span class="st">'Pitch only'</span>),</span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a>        Patch(facecolor<span class="op">=</span><span class="st">'white'</span>, edgecolor<span class="op">=</span><span class="st">'#33bb55'</span>, linewidth<span class="op">=</span><span class="dv">3</span>, label<span class="op">=</span><span class="st">'Time only'</span>),</span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>        Patch(facecolor<span class="op">=</span><span class="st">'white'</span>, edgecolor<span class="op">=</span><span class="st">'#dd3333'</span>, linewidth<span class="op">=</span><span class="dv">3</span>, label<span class="op">=</span><span class="st">'Pitch + Time'</span>),</span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a>    fig.legend(handles<span class="op">=</span>legend_items, loc<span class="op">=</span><span class="st">'lower center'</span>, ncol<span class="op">=</span><span class="dv">3</span>, fontsize<span class="op">=</span><span class="dv">16</span>,</span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a>               frameon<span class="op">=</span><span class="va">False</span>, bbox_to_anchor<span class="op">=</span>(<span class="fl">0.5</span>, <span class="op">-</span><span class="fl">0.02</span>))</span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a>    plt.subplots_adjust(bottom<span class="op">=</span><span class="fl">0.06</span>)</span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="b0141068-f02a-489f-b3a9-b10d46800497" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># test code</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>ds <span class="op">=</span> BlobShiftDataset()</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>dl <span class="op">=</span> DataLoader(ds, batch_size<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>a, c1, c2, t, s, d1, d2 <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(dl)) <span class="co"># augment_batch(8)</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>show_triplets(a, c1, c2, t, s, d1, d2)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4c3934d51ab142ed98f11b257a6deece","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11_toy_factorization_files/figure-html/cell-8-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="encoder-tiny-convnet-latent-vector" class="level2">
<h2 class="anchored" data-anchor-id="encoder-tiny-convnet-latent-vector">Encoder: tiny ConvNet → latent vector</h2>
<div id="c99841cc-3eb4-47f7-8f53-644770ca67de" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ToyEncoder(nn.Module):</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, latent_dim<span class="op">=</span><span class="dv">16</span>):</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.net <span class="op">=</span> nn.Sequential(</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(<span class="dv">1</span>, <span class="dv">16</span>, <span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>), nn.GELU(),          <span class="co"># 16x16</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(<span class="dv">16</span>, <span class="dv">32</span>, <span class="dv">3</span>, stride<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="dv">1</span>), nn.GELU(),  <span class="co"># 8x8</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(<span class="dv">32</span>, <span class="dv">64</span>, <span class="dv">3</span>, stride<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="dv">1</span>), nn.GELU(),  <span class="co"># 4x4</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(<span class="dv">64</span>,  <span class="dv">64</span>, <span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>), nn.GELU(),           <span class="co"># 4x4</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>            nn.AdaptiveAvgPool2d(<span class="dv">1</span>), nn.Flatten(),</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">64</span>, latent_dim),</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x): <span class="cf">return</span> <span class="va">self</span>.net(x)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="b3" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>enc <span class="op">=</span> ToyEncoder().to(device)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Params: </span><span class="sc">{</span><span class="bu">sum</span>(p.numel() <span class="cf">for</span> p <span class="kw">in</span> enc.parameters())<span class="sc">:,}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Params: 61,264</code></pre>
</div>
</div>
</section>
<section id="loss-cosine-factorization-objective" class="level2">
<h2 class="anchored" data-anchor-id="loss-cosine-factorization-objective">Loss: cosine factorization objective</h2>
<div id="b4" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> factorization_loss(z_anchor, z_crop1, z_crop2, targets):</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Cosine-similarity loss on difference vectors.</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="co">    targets: +1 (parallel), -1 (anti-parallel), 0 (orthogonal)"""</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    d1 <span class="op">=</span> z_crop1 <span class="op">-</span> z_anchor  <span class="co"># (B, D)</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>    d2 <span class="op">=</span> z_crop2 <span class="op">-</span> z_anchor  <span class="co"># (B, D)</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    cos <span class="op">=</span> F.cosine_similarity(d1, d2, dim<span class="op">=-</span><span class="dv">1</span>)  <span class="co"># (B,)</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> ((cos <span class="op">-</span> targets) <span class="op">**</span> <span class="dv">2</span>).mean()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="lejepa-too" class="level2">
<h2 class="anchored" data-anchor-id="lejepa-too">LeJEPA too?</h2>
<p>To make this slightly less of a toy model and more like the full system, we can also turn on the LeJEPA loss (Balestriero &amp; LeCun, 2025), which consists of attracting similar crops(/“views”) and a sigreg loss to prevent collapse.</p>
<div id="3ba01df8" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> safe_mean(t, dim<span class="op">=</span><span class="va">None</span>): </span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""safe replacement for torch.mean( ). (Don't need it for this NB, but I use it elsewhere in my project.) """</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> t.mean(dim<span class="op">=</span>dim) <span class="cf">if</span> t.numel() <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="fl">0.0</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> attraction_loss(z1, z2,  <span class="co"># embeddings of two "views" of the same thing (in batches)</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>                    deltas<span class="op">=</span><span class="va">None</span>,   <span class="co"># optional/</span><span class="al">TBD</span><span class="co">: info on semantic 'distance' between z1 &amp; z2</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>                    tau <span class="op">=</span> <span class="fl">100.0</span>):    <span class="co"># inverse strength of fall-off for delta distances, big=slower</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">"How we pull similar 'views' together"</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> deltas <span class="kw">is</span> <span class="va">None</span>: <span class="cf">return</span> safe_mean( (z1 <span class="op">-</span> z2).square() )</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>    delta_diag <span class="op">=</span> (deltas<span class="op">**</span><span class="dv">2</span>).<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>    delta_fac <span class="op">=</span> torch.exp(<span class="op">-</span>delta_diag <span class="op">/</span> tau) <span class="co"># less attraction for more 'distant' views</span></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>    <span class="co">#delta_fac = 1/(1 + delta_diag/tau)  # longer tail than exp</span></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> safe_mean( (z1 <span class="op">-</span> z2).square() <span class="op">*</span> delta_fac.unsqueeze(<span class="op">-</span><span class="dv">1</span>) )</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> SIGReg(x, global_step, num_slices<span class="op">=</span><span class="dv">256</span>):</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""SIGReg with Epps-Pulley statistic. x is (N, K) tensor."""</span></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> x.device</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>    g <span class="op">=</span> torch.Generator(device<span class="op">=</span>device).manual_seed(global_step)</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>    proj_shape <span class="op">=</span> (x.size(<span class="dv">1</span>), num_slices)</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>    A <span class="op">=</span> torch.randn(proj_shape, generator<span class="op">=</span>g, device<span class="op">=</span>device)</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>    A <span class="op">=</span> A <span class="op">/</span> (A.norm(dim<span class="op">=</span><span class="dv">0</span>, keepdim<span class="op">=</span><span class="va">True</span>) <span class="op">+</span> <span class="fl">1e-10</span>)  <span class="co"># normalize columns</span></span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Epps-Pulley statistic</span></span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>    t <span class="op">=</span> torch.linspace(<span class="op">-</span><span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">17</span>, device<span class="op">=</span>device) <span class="co"># values used in LeJEPA paper, worked for SSLtoy</span></span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>    exp_f <span class="op">=</span> torch.exp(<span class="op">-</span><span class="fl">0.5</span> <span class="op">*</span> t<span class="op">**</span><span class="dv">2</span>)  <span class="co"># theoretical CF for N(0,1)</span></span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a>    x_t <span class="op">=</span> (x <span class="op">@</span> A).unsqueeze(<span class="dv">2</span>) <span class="op">*</span> t  <span class="co"># (N, M, T)</span></span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>    ecf <span class="op">=</span> (torch.exp(<span class="ot">1j</span> <span class="op">*</span> x_t).mean(dim<span class="op">=</span><span class="dv">0</span>)).<span class="bu">abs</span>()  <span class="co"># empirical CF</span></span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a>    diff <span class="op">=</span> (ecf <span class="op">-</span> exp_f).<span class="bu">abs</span>().square().mul(exp_f)  <span class="co"># weighted L2 distance</span></span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a>    <span class="co">#N = x.size(0)  # With respect to Yann: Don't scale by N because then if you change the batch size you have to retune lambd by hand ugh</span></span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a>    T <span class="op">=</span> torch.trapz(diff, t, dim<span class="op">=</span><span class="dv">1</span>).<span class="bu">sum</span>() <span class="co">#* N  # sum here is over num slices, not data points</span></span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> T</span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> LeJEPA(z1, z2, global_step, lambd<span class="op">=</span><span class="fl">0.5</span>, deltas<span class="op">=</span><span class="va">None</span>): </span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a>    <span class="co">"Main LeJEPA loss function"</span></span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a>    sim <span class="op">=</span> attraction_loss(z1, z2, deltas<span class="op">=</span>deltas)</span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a>    sigreg <span class="op">=</span> SIGReg( torch.cat((z1, z2), dim<span class="op">=</span><span class="dv">0</span>), global_step ) <span class="op">*</span> <span class="dv">1</span> <span class="co"># normalize to similar scale as sim</span></span>
<span id="cb14-37"><a href="#cb14-37" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {<span class="st">'loss'</span>: (<span class="dv">1</span><span class="op">-</span>lambd)<span class="op">*</span>sim <span class="op">+</span> lambd<span class="op">*</span>sigreg, <span class="st">'sim'</span>:sim.item(), <span class="st">'sigreg'</span>:sigreg.item()}</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="training-loop" class="level2">
<h2 class="anchored" data-anchor-id="training-loop">Training loop</h2>
<div id="d561ff54-ecfc-4a98-9a70-2835801dc0c7" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train(enc, n_steps<span class="op">=</span><span class="dv">2000</span>, batch_size<span class="op">=</span><span class="dv">1024</span>, lr<span class="op">=</span><span class="fl">4e-3</span>, log_every<span class="op">=</span><span class="dv">100</span>, num_workers<span class="op">=</span><span class="dv">4</span>, use_jepa<span class="op">=</span><span class="va">False</span>, use_wandb<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>    opt <span class="op">=</span> torch.optim.Adam(enc.parameters(), lr<span class="op">=</span>lr)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>    ds <span class="op">=</span> BlobShiftDataset(epoch_size<span class="op">=</span>n_steps <span class="op">*</span> batch_size)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>    dl <span class="op">=</span> torch.utils.data.DataLoader(ds, batch_size<span class="op">=</span>batch_size, num_workers<span class="op">=</span>num_workers, pin_memory<span class="op">=</span>(device <span class="op">!=</span> <span class="st">'cpu'</span>))</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> use_wandb <span class="kw">and</span> HAS_WANDB:</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>        wandb.init(project<span class="op">=</span><span class="st">"toy-factorization"</span>, config<span class="op">=</span><span class="bu">dict</span>(n_steps<span class="op">=</span>n_steps, batch_size<span class="op">=</span>batch_size, lr<span class="op">=</span>lr, latent_dim<span class="op">=</span><span class="dv">8</span>))</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>    losses, fact_losses, jepa_losses <span class="op">=</span> [], [], []</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> step, (a, c1, c2, t, s, d1, d2) <span class="kw">in</span> <span class="bu">enumerate</span>(tqdm(dl)):</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>        a, c1, c2, t <span class="op">=</span> a.to(device), c1.to(device), c2.to(device), t.to(device)</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>        za, z1, z2 <span class="op">=</span> enc(a), enc(c1), enc(c2)</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>        fact_loss <span class="op">=</span> factorization_loss(za, z1, z2, t)</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> fact_loss</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> use_jepa:</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>            jepa_loss <span class="op">=</span> LeJEPA(za, z1, step)[<span class="st">'loss'</span>]  <span class="op">+</span> LeJEPA(za, z2, step)[<span class="st">'loss'</span>] </span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> loss <span class="op">+</span> <span class="fl">0.2</span><span class="op">*</span>jepa_loss</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>        opt.zero_grad()<span class="op">;</span> loss.backward()<span class="op">;</span> opt.step()</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>        losses.append(loss.item())</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>        fact_losses.append(fact_loss.item())</span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> use_jepa: jepa_losses.append(jepa_loss.item())</span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> step <span class="op">%</span> log_every <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"step </span><span class="sc">{</span>step<span class="sc">:4d}</span><span class="ss">  loss=</span><span class="sc">{</span>loss<span class="sc">.</span>item()<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> HAS_WANDB <span class="kw">and</span> wandb.run <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>: wandb.log({<span class="st">"loss"</span>: loss.item(), <span class="st">"fact"</span>:fact_loss.item(), <span class="st">"jepa"</span>:jepa_loss.item() <span class="cf">if</span> use_jepa <span class="cf">else</span> <span class="fl">0.0</span>, <span class="st">"step"</span>: step})</span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> HAS_WANDB <span class="kw">and</span> wandb.run <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>: wandb.finish()</span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> losses, fact_losses, jepa_losses</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>NOTE: with <code>use_jepa=True</code>, you’ll need 10,000 steps or more.</p>
<div id="b5" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>losses, fact_losses, jepa_losses <span class="op">=</span> train(enc, n_steps<span class="op">=</span><span class="dv">5000</span>, use_wandb<span class="op">=</span><span class="va">True</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre><span class="ansi-blue-fg ansi-bold">wandb</span>: [wandb.login()] Loaded credentials for https://api.wandb.ai from /home/shawley/.netrc.

<span class="ansi-blue-fg ansi-bold">wandb</span>: Currently logged in as: <span class="ansi-yellow-fg">drscotthawley</span> to <span class="ansi-green-fg">https://api.wandb.ai</span>. Use <span class="ansi-bold">`wandb login --relogin`</span> to force relogin
</pre>
</div>
</div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">
Tracking run with wandb version 0.24.2
</div>
<div class="cell-output cell-output-display">
Run data is saved locally in <code>/home/shawley/github/midi-rae/nbs/wandb/run-20260226_231124-frmov01u</code>
</div>
<div class="cell-output cell-output-display">
Syncing run <strong><a href="https://wandb.ai/drscotthawley/toy-factorization/runs/frmov01u" target="_blank">spring-dust-17</a></strong> to <a href="https://wandb.ai/drscotthawley/toy-factorization" target="_blank">Weights &amp; Biases</a> (<a href="https://wandb.me/developer-guide" target="_blank">docs</a>)<br>
</div>
<div class="cell-output cell-output-display">
 View project at <a href="https://wandb.ai/drscotthawley/toy-factorization" target="_blank">https://wandb.ai/drscotthawley/toy-factorization</a>
</div>
<div class="cell-output cell-output-display">
 View run at <a href="https://wandb.ai/drscotthawley/toy-factorization/runs/frmov01u" target="_blank">https://wandb.ai/drscotthawley/toy-factorization/runs/frmov01u</a>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"9491375a82704e8992e35e69a8d179de","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>step    0  loss=0.8981
step  100  loss=0.1192
step  200  loss=0.0714
step  300  loss=0.0528
step  400  loss=0.0453
step  500  loss=0.0498
step  600  loss=0.0390
step  700  loss=0.0405
step  800  loss=0.0360
step  900  loss=0.0394
step 1000  loss=0.0325
step 1100  loss=0.0308
step 1200  loss=0.0316
step 1300  loss=0.0341
step 1400  loss=0.0313
step 1500  loss=0.0307
step 1600  loss=0.0278
step 1700  loss=0.0299
step 1800  loss=0.0314
step 1900  loss=0.0279
step 2000  loss=0.0304
step 2100  loss=0.0314
step 2200  loss=0.0317
step 2300  loss=0.0290
step 2400  loss=0.0314
step 2500  loss=0.0254
step 2600  loss=0.0330
step 2700  loss=0.0263
step 2800  loss=0.0271
step 2900  loss=0.0305
step 3000  loss=0.0248
step 3100  loss=0.0311
step 3200  loss=0.0313
step 3300  loss=0.0310
step 3400  loss=0.0279
step 3500  loss=0.0265
step 3600  loss=0.0297
step 3700  loss=0.0259
step 3800  loss=0.0230
step 3900  loss=0.0221
step 4000  loss=0.0221
step 4100  loss=0.0256
step 4200  loss=0.0217
step 4300  loss=0.0201
step 4400  loss=0.0247
step 4500  loss=0.0256
step 4600  loss=0.0244
step 4700  loss=0.0219
step 4800  loss=0.0208
step 4900  loss=0.0254</code></pre>
</div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">
<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class="wandb-row"><div class="wandb-col"><h3 class="anchored">Run history:</h3><br>
<table class="wandb caption-top table table-sm table-striped small">
<tbody>
<tr class="odd">
<td>loss</td>
<td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td>
</tr>
<tr class="even">
<td>step</td>
<td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td>
</tr>
</tbody>
</table>
<br></div><div class="wandb-col"><h3 class="anchored">Run summary:</h3><br>
<table class="wandb caption-top table table-sm table-striped small">
<tbody>
<tr class="odd">
<td>loss</td>
<td>0.02539</td>
</tr>
<tr class="even">
<td>step</td>
<td>4900</td>
</tr>
</tbody>
</table>
<br></div></div>
</div>
<div class="cell-output cell-output-display">
 View run <strong style="color:#cdcd00">spring-dust-17</strong> at: <a href="https://wandb.ai/drscotthawley/toy-factorization/runs/frmov01u" target="_blank">https://wandb.ai/drscotthawley/toy-factorization/runs/frmov01u</a><br> View project at: <a href="https://wandb.ai/drscotthawley/toy-factorization" target="_blank">https://wandb.ai/drscotthawley/toy-factorization</a><br>Synced 5 W&amp;B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
</div>
<div class="cell-output cell-output-display">
Find logs at: <code>./wandb/run-20260226_231124-frmov01u/logs</code>
</div>
</div>
</section>
<section id="loss-curve" class="level2">
<h2 class="anchored" data-anchor-id="loss-curve">Loss curve</h2>
<div id="b6" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">3</span>))</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>plt.plot(losses, alpha<span class="op">=</span><span class="fl">0.3</span>, label<span class="op">=</span><span class="st">'raw'</span>)</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>plt.loglog(np.convolve(losses, np.ones(<span class="dv">50</span>)<span class="op">/</span><span class="dv">50</span>, mode<span class="op">=</span><span class="st">'valid'</span>), label<span class="op">=</span><span class="st">'smoothed'</span>)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'step'</span>)<span class="op">;</span> plt.ylabel(<span class="st">'loss'</span>)<span class="op">;</span> plt.legend()<span class="op">;</span> plt.title(<span class="st">'Factorization Loss'</span>)</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()<span class="op">;</span> plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11_toy_factorization_files/figure-html/cell-15-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="visualization-pitch-time-difference-vectors-separate-cleanly" class="level2">
<h2 class="anchored" data-anchor-id="visualization-pitch-time-difference-vectors-separate-cleanly">Visualization: pitch &amp; time difference vectors separate cleanly</h2>
<div id="19caeeaa-ba07-4592-98e6-03f4180d2e8b" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="at">@torch.no_grad</span>()</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> collect_diff_vectors(enc, n<span class="op">=</span><span class="dv">500</span>, sz<span class="op">=</span><span class="dv">16</span>, max_shift<span class="op">=</span><span class="dv">4</span>):</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Collect difference vectors, with same-sign and opposite-sign pairs from the SAME base image."""</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>    pitch_same, pitch_opp, time_same, time_opp <span class="op">=</span> [], [], [], []</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    pitch_d, time_d <span class="op">=</span> [], []</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(n):</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>        img <span class="op">=</span> make_blob(sz).unsqueeze(<span class="dv">0</span>).to(device)</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>        s1 <span class="op">=</span> torch.randint(<span class="dv">1</span>, max_shift<span class="op">+</span><span class="dv">1</span>, (<span class="dv">1</span>,)).item()</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>        s2 <span class="op">=</span> torch.randint(<span class="dv">1</span>, max_shift<span class="op">+</span><span class="dv">1</span>, (<span class="dv">1</span>,)).item()</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">while</span> s2 <span class="op">==</span> s1: s2 <span class="op">=</span> torch.randint(<span class="dv">1</span>, max_shift<span class="op">+</span><span class="dv">1</span>, (<span class="dv">1</span>,)).item()</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>        za <span class="op">=</span> enc(img)</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> dim, same_list, opp_list, d_list <span class="kw">in</span> [</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>            (<span class="dv">2</span>, pitch_same, pitch_opp, pitch_d),</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>            (<span class="dv">3</span>, time_same, time_opp, time_d)]:</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>            zp1 <span class="op">=</span> enc(shift_no_wrap(img, shifts<span class="op">=+</span>s1, dims<span class="op">=</span>dim))</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>            zp2 <span class="op">=</span> enc(shift_no_wrap(img, shifts<span class="op">=+</span>s2, dims<span class="op">=</span>dim))</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>            zn1 <span class="op">=</span> enc(shift_no_wrap(img, shifts<span class="op">=-</span>s1, dims<span class="op">=</span>dim))</span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>            d1, d2, d3 <span class="op">=</span> zp1 <span class="op">-</span> za, zp2 <span class="op">-</span> za, zn1 <span class="op">-</span> za</span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>            same_list.append(F.cosine_similarity(d1, d2, dim<span class="op">=-</span><span class="dv">1</span>).item())  <span class="co"># same sign</span></span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>            opp_list.append(F.cosine_similarity(d1, d3, dim<span class="op">=-</span><span class="dv">1</span>).item())   <span class="co"># opposite sign</span></span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>            d_list.append(d1.squeeze().cpu())</span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>            d_list.append(d3.squeeze().cpu())</span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>    pitch_d, time_d <span class="op">=</span> torch.stack(pitch_d), torch.stack(time_d)</span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a>    cos_cross <span class="op">=</span> F.cosine_similarity(pitch_d[:<span class="bu">len</span>(time_d)], time_d[:<span class="bu">len</span>(pitch_d)], dim<span class="op">=-</span><span class="dv">1</span>).numpy()</span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pitch_d, time_d, np.array(pitch_same), np.array(pitch_opp), np.array(time_same), np.array(time_opp), cos_cross</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-error">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">NameError</span>                                 Traceback (most recent call last)
<span class="ansi-cyan-fg">Cell</span><span class="ansi-cyan-fg"> </span><span class="ansi-green-fg">In[13]</span><span class="ansi-green-fg">, line 1</span>
<span class="ansi-green-fg">----&gt; </span><span class="ansi-green-fg">1</span> <span style="color:rgb(175,0,255)">@torch</span>.no_grad()
<span class="ansi-green-fg">      2</span> <span style="font-weight:bold;color:rgb(0,135,0)">def</span><span style="color:rgb(188,188,188)"> </span><span class="ansi-blue-fg">collect_diff_vectors</span>(enc, n=<span class="ansi-green-fg">500</span>, sz=<span class="ansi-green-fg">16</span>, max_shift=<span class="ansi-green-fg">4</span>):
<span class="ansi-green-fg">      3</span> <span style="color:rgb(188,188,188)">    </span><span style="font-style:italic" class="ansi-yellow-fg">"""Collect difference vectors, with same-sign and opposite-sign pairs from the SAME base image."""</span>
<span class="ansi-green-fg">      4</span>     pitch_same, pitch_opp, time_same, time_opp = [], [], [], []

<span class="ansi-red-fg">NameError</span>: name 'torch' is not defined</pre>
</div>
</div>
</div>
<div id="b7" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>pitch_d, time_d, ps, po, ts, to_, cos_cross <span class="op">=</span> collect_diff_vectors(enc)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Collected: pitch=</span><span class="sc">{</span>pitch_d<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">, time=</span><span class="sc">{</span>time_d<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Collected: pitch=torch.Size([1000, 16]), time=torch.Size([1000, 16])</code></pre>
</div>
</div>
<div id="b8" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>all_diffs <span class="op">=</span> torch.cat([pitch_d, time_d], dim<span class="op">=</span><span class="dv">0</span>).numpy()</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> [<span class="st">'pitch'</span>] <span class="op">*</span> <span class="bu">len</span>(pitch_d) <span class="op">+</span> [<span class="st">'time'</span>] <span class="op">*</span> <span class="bu">len</span>(time_d)</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>).fit(all_diffs)</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>proj <span class="op">=</span> pca.transform(all_diffs)</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">5</span>))</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a><span class="co"># PCA scatter  </span></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>all_diffs <span class="op">=</span> torch.cat([pitch_d, time_d], dim<span class="op">=</span><span class="dv">0</span>).numpy()</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>).fit(all_diffs)</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>proj <span class="op">=</span> pca.transform(all_diffs)</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="bu">len</span>(pitch_d)</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].scatter(proj[:n, <span class="dv">0</span>], proj[:n, <span class="dv">1</span>], alpha<span class="op">=</span><span class="fl">0.3</span>, s<span class="op">=</span><span class="dv">10</span>, label<span class="op">=</span><span class="st">'pitch Δ'</span>, c<span class="op">=</span><span class="st">'blue'</span>)</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].scatter(proj[n:, <span class="dv">0</span>], proj[n:, <span class="dv">1</span>], alpha<span class="op">=</span><span class="fl">0.3</span>, s<span class="op">=</span><span class="dv">10</span>, label<span class="op">=</span><span class="st">'time Δ'</span>, c<span class="op">=</span><span class="st">'green'</span>)</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlabel(<span class="st">'PC1'</span>)<span class="op">;</span> axes[<span class="dv">0</span>].set_ylabel(<span class="st">'PC2'</span>)<span class="op">;</span> axes[<span class="dv">0</span>].legend()</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">'PCA of difference vectors'</span>)<span class="op">;</span> axes[<span class="dv">0</span>].set_aspect(<span class="st">'equal'</span>)</span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Histogram with all three distributions</span></span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> axes[<span class="dv">1</span>]</span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a>ax.hist(cos_cross, bins<span class="op">=</span><span class="dv">40</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">'pitch vs time (want ≈0)'</span>, density<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a>ax.hist(np.concatenate([ps, ts]), bins<span class="op">=</span><span class="dv">40</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">'same-sign (want ≈+1)'</span>, density<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a>ax.hist(np.concatenate([po, to_]), bins<span class="op">=</span><span class="dv">40</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">'opp-sign (want ≈−1)'</span>, density<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'cosine similarity'</span>)<span class="op">;</span> ax.legend()<span class="op">;</span> ax.set_title(<span class="st">'Cosine similarity distributions'</span>)</span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()<span class="op">;</span> plt.show()</span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-27"><a href="#cb22-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"target=+0: mean cos=</span><span class="sc">{</span>cos_cross<span class="sc">.</span>mean()<span class="sc">:.3f}</span><span class="ss">, mean |cos|=</span><span class="sc">{</span>np<span class="sc">.</span><span class="bu">abs</span>(cos_cross)<span class="sc">.</span>mean()<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb22-28"><a href="#cb22-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"target=+1: mean cos=</span><span class="sc">{</span>np<span class="sc">.</span>concatenate([ps,ts])<span class="sc">.</span>mean()<span class="sc">:.3f}</span><span class="ss">, mean |cos|=</span><span class="sc">{</span>np<span class="sc">.</span><span class="bu">abs</span>(np.concatenate([ps,ts]))<span class="sc">.</span>mean()<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb22-29"><a href="#cb22-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"target=-1: mean cos=</span><span class="sc">{</span>np<span class="sc">.</span>concatenate([po,to_])<span class="sc">.</span>mean()<span class="sc">:.3f}</span><span class="ss">, mean |cos|=</span><span class="sc">{</span>np<span class="sc">.</span><span class="bu">abs</span>(np.concatenate([po,to_]))<span class="sc">.</span>mean()<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11_toy_factorization_files/figure-html/cell-18-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Mean |cos(pitch,time)|: 0.126  (ideal: 0)
Mean |cos(pitch,pitch)|: 0.883  (ideal: 1)
Mean |cos(time,time)|:  0.878  (ideal: 1)</code></pre>
</div>
</div>
</section>
<section id="results-summary" class="level2">
<h2 class="anchored" data-anchor-id="results-summary">Results summary</h2>
<p>The factorization objective works well. After training for 5,000 steps with batch size 1024 and lr=4e-3:</p>
<ul>
<li><strong>Cross-type cosine similarity</strong> (pitch vs time): mean |cos| = 0.116, tightly clustered around 0 ✅</li>
<li><strong>Same-sign cosine similarity</strong>: mean cos = 0.954, sharp peak near +1 ✅</li>
<li><strong>Opposite-sign cosine similarity</strong>: mean cos = −0.884, peak near −1 ✅</li>
<li><strong>Positive/negative alignment angles</strong>: pitch 162.8°, time 163.2° (ideal: 180°) ✅</li>
</ul>
<p>The PCA of difference vectors shows a clear cross shape, confirming pitch and time directions are approximately orthogonal in the learned latent space. The remaining ~17° deviation from perfect anti-parallelism is attributable to the asymmetric zero-padding introduced by <code>shift_no_wrap</code> (see probing section below).</p>
<section id="probing-the-1-asymmetry" class="level3">
<h3 class="anchored" data-anchor-id="probing-the-1-asymmetry">Probing the ±1 asymmetry</h3>
<p>Both pitch-vs-pitch and time-vs-time cosine distributions show stronger correlation on the +1 side than the −1 side. This is because <code>shift_no_wrap</code> introduces an asymmetry: same-sign shift pairs produce crops with zero-padding on the <strong>same</strong> side (structurally more similar), while opposite-sign pairs have padding on <strong>opposite</strong> sides (more visually different). The encoder maps the more-similar same-sign pairs more consistently, yielding a tighter +1 peak and a broader −1 peak.</p>
<div id="41b9db16-c88e-4de9-8a19-5f5e5c99e9c7" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="at">@torch.no_grad</span>()</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> collect_signed_diffs(enc, n<span class="op">=</span><span class="dv">500</span>, sz<span class="op">=</span><span class="dv">16</span>, max_shift<span class="op">=</span><span class="dv">4</span>):</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Collect diff vectors split by sign for both pitch and time."""</span></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>    results <span class="op">=</span> {<span class="st">'pitch_pos'</span>: [], <span class="st">'pitch_neg'</span>: [], <span class="st">'time_pos'</span>: [], <span class="st">'time_neg'</span>: []}</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(n):</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>        img <span class="op">=</span> make_blob(sz).unsqueeze(<span class="dv">0</span>).to(device)</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>        s <span class="op">=</span> torch.randint(<span class="dv">1</span>, max_shift<span class="op">+</span><span class="dv">1</span>, (<span class="dv">1</span>,)).item()</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>        za <span class="op">=</span> enc(img)</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> dim, name <span class="kw">in</span> [(<span class="dv">2</span>, <span class="st">'pitch'</span>), (<span class="dv">3</span>, <span class="st">'time'</span>)]:</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> sign, label <span class="kw">in</span> [(<span class="dv">1</span>, <span class="st">'pos'</span>), (<span class="op">-</span><span class="dv">1</span>, <span class="st">'neg'</span>)]:</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>                zs <span class="op">=</span> enc(shift_no_wrap(img, shifts<span class="op">=</span>sign<span class="op">*</span>s, dims<span class="op">=</span>dim))</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>                results[<span class="ss">f'</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">_</span><span class="sc">{</span>label<span class="sc">}</span><span class="ss">'</span>].append((zs <span class="op">-</span> za).squeeze().cpu())</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {k: torch.stack(v) <span class="cf">for</span> k, v <span class="kw">in</span> results.items()}</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>diffs <span class="op">=</span> collect_signed_diffs(enc)</span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name <span class="kw">in</span> [<span class="st">'pitch'</span>, <span class="st">'time'</span>]:</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>    mean_pos <span class="op">=</span> diffs[<span class="ss">f'</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">_pos'</span>].mean(dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>    mean_neg <span class="op">=</span> diffs[<span class="ss">f'</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">_neg'</span>].mean(dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>    cos <span class="op">=</span> F.cosine_similarity(mean_pos.unsqueeze(<span class="dv">0</span>), mean_neg.unsqueeze(<span class="dv">0</span>)).item()</span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>    angle <span class="op">=</span> np.degrees(np.arccos(np.clip(cos, <span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)))</span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">: cos(mean_pos, mean_neg) = </span><span class="sc">{</span>cos<span class="sc">:.3f}</span><span class="ss">, angle = </span><span class="sc">{</span>angle<span class="sc">:.1f}</span><span class="ss">° (ideal: 180°)"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>pitch: cos(mean_pos, mean_neg) = -0.955, angle = 162.8° (ideal: 180°)
time: cos(mean_pos, mean_neg) = -0.957, angle = 163.2° (ideal: 180°)</code></pre>
</div>
</div>
<div id="5dd9f41a-2b98-47f9-955b-17328c14c217" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>pca.explained_variance_ratio_[:<span class="dv">2</span>]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>array([0.27807263, 0.2644205 ], dtype=float32)</code></pre>
</div>
</div>
</section>
<section id="svd-on-shift-grids" class="level3">
<h3 class="anchored" data-anchor-id="svd-on-shift-grids">SVD on shift grids</h3>
<p>For each blob, we encode a full grid of (dy, dx) shifts and reshape the resulting embedding tensor for SVD. The first singular value dominates (60–80% of total), with rapid dropoff after 2–3 components — consistent with an approximately rank-1 (tensor-product) factorization. This confirms the soft orthogonality loss pushes the representation toward factored structure without enforcing it rigidly.</p>
<div id="58a1945d-abe8-43ac-a3cc-42e278eb8ecb" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="at">@torch.no_grad</span>()</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> grid_embeddings(enc, n_blobs<span class="op">=</span><span class="dv">50</span>, sz<span class="op">=</span><span class="dv">16</span>, max_shift<span class="op">=</span><span class="dv">4</span>):</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Encode a grid of (dy, dx) shifts for each blob."""</span></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>    shifts <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(<span class="op">-</span>max_shift, max_shift<span class="op">+</span><span class="dv">1</span>))  <span class="co"># e.g. -4..+4 = 9 values</span></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>    all_Z <span class="op">=</span> []</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(n_blobs):</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>        img <span class="op">=</span> make_blob(sz).unsqueeze(<span class="dv">0</span>).to(device)</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>        Z <span class="op">=</span> []</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> dy <span class="kw">in</span> shifts:</span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> dx <span class="kw">in</span> shifts:</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>                shifted <span class="op">=</span> shift_no_wrap(shift_no_wrap(img, shifts<span class="op">=</span>dy, dims<span class="op">=</span><span class="dv">2</span>), shifts<span class="op">=</span>dx, dims<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>                z <span class="op">=</span> enc(shifted).squeeze().cpu()</span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a>                Z.append(z)</span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a>        all_Z.append(torch.stack(Z).reshape(<span class="bu">len</span>(shifts), <span class="bu">len</span>(shifts), <span class="op">-</span><span class="dv">1</span>))</span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> torch.stack(all_Z), shifts  <span class="co"># (n_blobs, n_dy, n_dx, latent_dim)</span></span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a>Z, shifts <span class="op">=</span> grid_embeddings(enc)</span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a>n_dy, n_dx, latent <span class="op">=</span> Z.shape[<span class="dv">1</span>], Z.shape[<span class="dv">2</span>], Z.shape[<span class="dv">3</span>]</span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Z shape: </span><span class="sc">{</span>Z<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">  (blobs, dy, dx, latent)"</span>)</span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-21"><a href="#cb28-21" aria-hidden="true" tabindex="-1"></a><span class="co"># For each blob, reshape to (n_dy, n_dx*latent) and get singular values</span></span>
<span id="cb28-22"><a href="#cb28-22" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">4</span>))</span>
<span id="cb28-23"><a href="#cb28-23" aria-hidden="true" tabindex="-1"></a>all_sv <span class="op">=</span> []</span>
<span id="cb28-24"><a href="#cb28-24" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(Z)):</span>
<span id="cb28-25"><a href="#cb28-25" aria-hidden="true" tabindex="-1"></a>    M <span class="op">=</span> Z[i].reshape(n_dy, n_dx <span class="op">*</span> latent).numpy()</span>
<span id="cb28-26"><a href="#cb28-26" aria-hidden="true" tabindex="-1"></a>    sv <span class="op">=</span> np.linalg.svd(M, compute_uv<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb28-27"><a href="#cb28-27" aria-hidden="true" tabindex="-1"></a>    sv_normed <span class="op">=</span> sv <span class="op">/</span> sv.<span class="bu">sum</span>()</span>
<span id="cb28-28"><a href="#cb28-28" aria-hidden="true" tabindex="-1"></a>    all_sv.append(sv_normed)</span>
<span id="cb28-29"><a href="#cb28-29" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">0</span>].plot(sv_normed, alpha<span class="op">=</span><span class="fl">0.15</span>, color<span class="op">=</span><span class="st">'blue'</span>)</span>
<span id="cb28-30"><a href="#cb28-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-31"><a href="#cb28-31" aria-hidden="true" tabindex="-1"></a>mean_sv <span class="op">=</span> np.stack(all_sv).mean(<span class="dv">0</span>)</span>
<span id="cb28-32"><a href="#cb28-32" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].plot(mean_sv, color<span class="op">=</span><span class="st">'red'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'mean'</span>)</span>
<span id="cb28-33"><a href="#cb28-33" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlabel(<span class="st">'singular value index'</span>)<span class="op">;</span> axes[<span class="dv">0</span>].set_ylabel(<span class="st">'fraction of total'</span>)</span>
<span id="cb28-34"><a href="#cb28-34" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">'Singular values: Z reshaped as (pitch, time·latent)'</span>)</span>
<span id="cb28-35"><a href="#cb28-35" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].legend()</span>
<span id="cb28-36"><a href="#cb28-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-37"><a href="#cb28-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Same but transposed: (n_dx, n_dy*latent)</span></span>
<span id="cb28-38"><a href="#cb28-38" aria-hidden="true" tabindex="-1"></a>all_sv_t <span class="op">=</span> []</span>
<span id="cb28-39"><a href="#cb28-39" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(Z)):</span>
<span id="cb28-40"><a href="#cb28-40" aria-hidden="true" tabindex="-1"></a>    M <span class="op">=</span> Z[i].permute(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">2</span>).reshape(n_dx, n_dy <span class="op">*</span> latent).numpy()</span>
<span id="cb28-41"><a href="#cb28-41" aria-hidden="true" tabindex="-1"></a>    sv <span class="op">=</span> np.linalg.svd(M, compute_uv<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb28-42"><a href="#cb28-42" aria-hidden="true" tabindex="-1"></a>    sv_normed <span class="op">=</span> sv <span class="op">/</span> sv.<span class="bu">sum</span>()</span>
<span id="cb28-43"><a href="#cb28-43" aria-hidden="true" tabindex="-1"></a>    all_sv_t.append(sv_normed)</span>
<span id="cb28-44"><a href="#cb28-44" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">1</span>].plot(sv_normed, alpha<span class="op">=</span><span class="fl">0.15</span>, color<span class="op">=</span><span class="st">'green'</span>)</span>
<span id="cb28-45"><a href="#cb28-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-46"><a href="#cb28-46" aria-hidden="true" tabindex="-1"></a>mean_sv_t <span class="op">=</span> np.stack(all_sv_t).mean(<span class="dv">0</span>)</span>
<span id="cb28-47"><a href="#cb28-47" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].plot(mean_sv_t, color<span class="op">=</span><span class="st">'red'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'mean'</span>)</span>
<span id="cb28-48"><a href="#cb28-48" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlabel(<span class="st">'singular value index'</span>)<span class="op">;</span> axes[<span class="dv">1</span>].set_ylabel(<span class="st">'fraction of total'</span>)</span>
<span id="cb28-49"><a href="#cb28-49" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">'Singular values: Z reshaped as (time, pitch·latent)'</span>)</span>
<span id="cb28-50"><a href="#cb28-50" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].legend()</span>
<span id="cb28-51"><a href="#cb28-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-52"><a href="#cb28-52" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()<span class="op">;</span> plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Z shape: torch.Size([50, 9, 9, 16])  (blobs, dy, dx, latent)</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11_toy_factorization_files/figure-html/cell-21-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="deeper-analysis-kernel-pca-and-svd" class="level2">
<h2 class="anchored" data-anchor-id="deeper-analysis-kernel-pca-and-svd">Deeper analysis: Kernel PCA and SVD</h2>
<p>The cosine histograms confirm that the soft loss achieves the desired geometric relationships. But does the latent space admit a <strong>tensor-product</strong> structure — i.e., can embeddings be decomposed into pitch ⊗ time components?</p>
<p>We use two complementary analyses:</p>
<ol type="1">
<li><p><strong>Kernel PCA</strong> with an RBF kernel (inspired by Albinet’s (2026) connection between soft constraints and eigenstructure via kernel methods). The RBF kernel can reveal nonlinear factored structure that linear PCA would miss. Results show that the first two kernel principal components cleanly separate pitch and time with orthogonal gradients, while kPC3–4 contain no factor-related structure — confirming a 2D factored subspace.</p></li>
<li><p><strong>SVD on a grid of shift embeddings</strong>: For each blob, we encode a full grid of (pitch, time) shifts and reshape as a matrix. The first singular value captures 60–80% of the total energy, with most of the remainder in just 2–3 components — indicating approximately low-rank (near tensor-product) structure in the learned embeddings.</p></li>
</ol>
<div id="770b9664-08f9-41d7-a293-2bc87e8b20a4" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># kernel pca </span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> KernelPCA</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a><span class="at">@torch.no_grad</span>()</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> kernel_pca_analysis(enc, n_blobs<span class="op">=</span><span class="dv">200</span>, sz<span class="op">=</span><span class="dv">16</span>, max_shift<span class="op">=</span><span class="dv">4</span>, gamma<span class="op">=</span><span class="fl">1.0</span>):</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Encode shifted blobs and apply kernel PCA to reveal nonlinear structure."""</span></span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>    shifts <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(<span class="op">-</span>max_shift, max_shift<span class="op">+</span><span class="dv">1</span>))</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>    embeddings, dy_labels, dx_labels <span class="op">=</span> [], [], []</span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(n_blobs):</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>        img <span class="op">=</span> make_blob(sz).unsqueeze(<span class="dv">0</span>).to(device)</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> dy <span class="kw">in</span> shifts:</span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> dx <span class="kw">in</span> shifts:</span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a>                shifted <span class="op">=</span> shift_no_wrap(shift_no_wrap(img, shifts<span class="op">=</span>dy, dims<span class="op">=</span><span class="dv">2</span>), shifts<span class="op">=</span>dx, dims<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a>                z <span class="op">=</span> enc(shifted).squeeze().cpu().numpy()</span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a>                embeddings.append(z)</span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a>                dy_labels.append(dy)</span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a>                dx_labels.append(dx)</span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> np.stack(embeddings)</span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a>    dy_labels, dx_labels <span class="op">=</span> np.array(dy_labels), np.array(dx_labels)</span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a>    kpca <span class="op">=</span> KernelPCA(n_components<span class="op">=</span><span class="dv">4</span>, kernel<span class="op">=</span><span class="st">'rbf'</span>, gamma<span class="op">=</span>gamma)</span>
<span id="cb30-23"><a href="#cb30-23" aria-hidden="true" tabindex="-1"></a>    Z <span class="op">=</span> kpca.fit_transform(X)</span>
<span id="cb30-24"><a href="#cb30-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-25"><a href="#cb30-25" aria-hidden="true" tabindex="-1"></a>    fig, axs <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">7</span>))</span>
<span id="cb30-26"><a href="#cb30-26" aria-hidden="true" tabindex="-1"></a>    axes <span class="op">=</span> axs.flatten()</span>
<span id="cb30-27"><a href="#cb30-27" aria-hidden="true" tabindex="-1"></a>    sc0 <span class="op">=</span> axes[<span class="dv">0</span>].scatter(Z[:, <span class="dv">0</span>], Z[:, <span class="dv">1</span>], c<span class="op">=</span>dy_labels, cmap<span class="op">=</span><span class="st">'coolwarm'</span>, s<span class="op">=</span><span class="dv">2</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb30-28"><a href="#cb30-28" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">0</span>].set_xlabel(<span class="st">'kPC1'</span>)<span class="op">;</span> axes[<span class="dv">0</span>].set_ylabel(<span class="st">'kPC2'</span>)</span>
<span id="cb30-29"><a href="#cb30-29" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">0</span>].set_title(<span class="st">'Colored by pitch shift (dy)'</span>)</span>
<span id="cb30-30"><a href="#cb30-30" aria-hidden="true" tabindex="-1"></a>    plt.colorbar(sc0, ax<span class="op">=</span>axes[<span class="dv">0</span>])</span>
<span id="cb30-31"><a href="#cb30-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-32"><a href="#cb30-32" aria-hidden="true" tabindex="-1"></a>    sc1 <span class="op">=</span> axes[<span class="dv">1</span>].scatter(Z[:, <span class="dv">0</span>], Z[:, <span class="dv">1</span>], c<span class="op">=</span>dx_labels, cmap<span class="op">=</span><span class="st">'PiYG'</span>, s<span class="op">=</span><span class="dv">2</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb30-33"><a href="#cb30-33" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">1</span>].set_xlabel(<span class="st">'kPC1'</span>)<span class="op">;</span> axes[<span class="dv">1</span>].set_ylabel(<span class="st">'kPC2'</span>)</span>
<span id="cb30-34"><a href="#cb30-34" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">1</span>].set_title(<span class="st">'Colored by time shift (dx)'</span>)</span>
<span id="cb30-35"><a href="#cb30-35" aria-hidden="true" tabindex="-1"></a>    plt.colorbar(sc1, ax<span class="op">=</span>axes[<span class="dv">1</span>])</span>
<span id="cb30-36"><a href="#cb30-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-37"><a href="#cb30-37" aria-hidden="true" tabindex="-1"></a>    sc2 <span class="op">=</span> axes[<span class="dv">2</span>].scatter(Z[:, <span class="dv">2</span>], Z[:, <span class="dv">3</span>], c<span class="op">=</span>dy_labels, cmap<span class="op">=</span><span class="st">'coolwarm'</span>, s<span class="op">=</span><span class="dv">2</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb30-38"><a href="#cb30-38" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">2</span>].set_xlabel(<span class="st">'kPC3'</span>)<span class="op">;</span> axes[<span class="dv">2</span>].set_ylabel(<span class="st">'kPC4'</span>)</span>
<span id="cb30-39"><a href="#cb30-39" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">2</span>].set_title(<span class="st">'kPC3-4, colored by pitch'</span>)</span>
<span id="cb30-40"><a href="#cb30-40" aria-hidden="true" tabindex="-1"></a>    plt.colorbar(sc2, ax<span class="op">=</span>axes[<span class="dv">2</span>])</span>
<span id="cb30-41"><a href="#cb30-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-42"><a href="#cb30-42" aria-hidden="true" tabindex="-1"></a>    sc3 <span class="op">=</span> axes[<span class="dv">3</span>].scatter(Z[:, <span class="dv">2</span>], Z[:, <span class="dv">3</span>], c<span class="op">=</span>dx_labels, cmap<span class="op">=</span><span class="st">'PiYG'</span>, s<span class="op">=</span><span class="dv">2</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb30-43"><a href="#cb30-43" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">3</span>].set_xlabel(<span class="st">'kPC3'</span>)<span class="op">;</span> axes[<span class="dv">2</span>].set_ylabel(<span class="st">'kPC4'</span>)</span>
<span id="cb30-44"><a href="#cb30-44" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">3</span>].set_title(<span class="st">'kPC3-4, colored by time'</span>)</span>
<span id="cb30-45"><a href="#cb30-45" aria-hidden="true" tabindex="-1"></a>    plt.colorbar(sc3, ax<span class="op">=</span>axes[<span class="dv">3</span>])</span>
<span id="cb30-46"><a href="#cb30-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-47"><a href="#cb30-47" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()<span class="op">;</span> plt.show()</span>
<span id="cb30-48"><a href="#cb30-48" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> kpca, Z, dy_labels, dx_labels</span>
<span id="cb30-49"><a href="#cb30-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-50"><a href="#cb30-50" aria-hidden="true" tabindex="-1"></a>kpca, Z, dy_lab, dx_lab <span class="op">=</span> kernel_pca_analysis(enc, gamma<span class="op">=</span><span class="fl">1.0</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11_toy_factorization_files/figure-html/cell-22-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="08a59918-77b0-4480-b47d-4c6f6718f3b7" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>uv pip install umap<span class="op">-</span>learn</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Using Python 3.10.12 environment at: /home/shawley/envs/midi-rae
Resolved 10 packages in 366ms                                        
Prepared 2 packages in 38ms                                              
Installed 2 packages in 2ms                                 
 + pynndescent==0.6.0
 + umap-learn==0.5.11</code></pre>
</div>
</div>
</section>
<section id="does-umap-show-us-anything" class="level2">
<h2 class="anchored" data-anchor-id="does-umap-show-us-anything">Does UMAP Show Us Anything?</h2>
<p>If the nonlinear PCA with the RBF kernel is showing a clean separation, does that mean that there’s a two-dimensional subspace manifold at work? Maybe UMAP can discover this manifold and show us something interesting.</p>
<p>Spoiler: No, This is pretty much a jumbled mess because the UMAP focuses on the local structure and twists everything around:</p>
<div id="2ff2c922-5269-49ef-b9c5-28aed7475600" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Umap </span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> umap</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="at">@torch.no_grad</span>()</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> umap_analysis(enc, n_blobs<span class="op">=</span><span class="dv">200</span>, sz<span class="op">=</span><span class="dv">16</span>, max_shift<span class="op">=</span><span class="dv">4</span>):</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>    shifts <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(<span class="op">-</span>max_shift, max_shift<span class="op">+</span><span class="dv">1</span>))</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>    embeddings, dy_labels, dx_labels <span class="op">=</span> [], [], []</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(n_blobs):</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>        img <span class="op">=</span> make_blob(sz).unsqueeze(<span class="dv">0</span>).to(device)</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> dy <span class="kw">in</span> shifts:</span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> dx <span class="kw">in</span> shifts:</span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a>                shifted <span class="op">=</span> shift_no_wrap(shift_no_wrap(img, shifts<span class="op">=</span>dy, dims<span class="op">=</span><span class="dv">2</span>), shifts<span class="op">=</span>dx, dims<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a>                z <span class="op">=</span> enc(shifted).squeeze().cpu().numpy()</span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a>                embeddings.append(z)</span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a>                dy_labels.append(dy)</span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a>                dx_labels.append(dx)</span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> np.stack(embeddings)</span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a>    dy_labels, dx_labels <span class="op">=</span> np.array(dy_labels), np.array(dx_labels)</span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a>    reducer <span class="op">=</span> umap.UMAP(n_components<span class="op">=</span><span class="dv">2</span>, n_neighbors<span class="op">=</span><span class="dv">15</span>, min_dist<span class="op">=</span><span class="fl">0.1</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a>    Z <span class="op">=</span> reducer.fit_transform(X)</span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true" tabindex="-1"></a>    fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">5</span>))</span>
<span id="cb33-24"><a href="#cb33-24" aria-hidden="true" tabindex="-1"></a>    sc0 <span class="op">=</span> axes[<span class="dv">0</span>].scatter(Z[:, <span class="dv">0</span>], Z[:, <span class="dv">1</span>], c<span class="op">=</span>dy_labels, cmap<span class="op">=</span><span class="st">'coolwarm'</span>, s<span class="op">=</span><span class="dv">2</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb33-25"><a href="#cb33-25" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">0</span>].set_title(<span class="st">'UMAP colored by pitch shift (dy)'</span>)</span>
<span id="cb33-26"><a href="#cb33-26" aria-hidden="true" tabindex="-1"></a>    plt.colorbar(sc0, ax<span class="op">=</span>axes[<span class="dv">0</span>])</span>
<span id="cb33-27"><a href="#cb33-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-28"><a href="#cb33-28" aria-hidden="true" tabindex="-1"></a>    sc1 <span class="op">=</span> axes[<span class="dv">1</span>].scatter(Z[:, <span class="dv">0</span>], Z[:, <span class="dv">1</span>], c<span class="op">=</span>dx_labels, cmap<span class="op">=</span><span class="st">'PiYG'</span>, s<span class="op">=</span><span class="dv">2</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb33-29"><a href="#cb33-29" aria-hidden="true" tabindex="-1"></a>    axes[<span class="dv">1</span>].set_title(<span class="st">'UMAP colored by time shift (dx)'</span>)</span>
<span id="cb33-30"><a href="#cb33-30" aria-hidden="true" tabindex="-1"></a>    plt.colorbar(sc1, ax<span class="op">=</span>axes[<span class="dv">1</span>])</span>
<span id="cb33-31"><a href="#cb33-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-32"><a href="#cb33-32" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()<span class="op">;</span> plt.show()</span>
<span id="cb33-33"><a href="#cb33-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> reducer, Z, dy_labels, dx_labels</span>
<span id="cb33-34"><a href="#cb33-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-35"><a href="#cb33-35" aria-hidden="true" tabindex="-1"></a>reducer, Z_umap, dy_lab, dx_lab <span class="op">=</span> umap_analysis(enc)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/shawley/envs/midi-rae/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11_toy_factorization_files/figure-html/cell-24-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>What if we went to 3D instead of 2D? Would it let us see more?</p>
<p>Answer: not really.</p>
<div id="94545178-9ee8-4172-adfe-f1c42d06afb2" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotly.graph_objects <span class="im">as</span> go</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="at">@torch.no_grad</span>()</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> umap_3d_analysis(enc, n_blobs<span class="op">=</span><span class="dv">200</span>, sz<span class="op">=</span><span class="dv">16</span>, max_shift<span class="op">=</span><span class="dv">4</span>):</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>    shifts <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(<span class="op">-</span>max_shift, max_shift<span class="op">+</span><span class="dv">1</span>))</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>    embeddings, dy_labels, dx_labels <span class="op">=</span> [], [], []</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(n_blobs):</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>        img <span class="op">=</span> make_blob(sz).unsqueeze(<span class="dv">0</span>).to(device)</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> dy <span class="kw">in</span> shifts:</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> dx <span class="kw">in</span> shifts:</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>                shifted <span class="op">=</span> shift_no_wrap(shift_no_wrap(img, shifts<span class="op">=</span>dy, dims<span class="op">=</span><span class="dv">2</span>), shifts<span class="op">=</span>dx, dims<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>                z <span class="op">=</span> enc(shifted).squeeze().cpu().numpy()</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a>                embeddings.append(z)</span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>                dy_labels.append(dy)</span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a>                dx_labels.append(dx)</span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> np.stack(embeddings)</span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a>    dy_labels, dx_labels <span class="op">=</span> np.array(dy_labels), np.array(dx_labels)</span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a>    reducer <span class="op">=</span> umap.UMAP(n_components<span class="op">=</span><span class="dv">3</span>, n_neighbors<span class="op">=</span><span class="dv">15</span>, min_dist<span class="op">=</span><span class="fl">0.1</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a>    coords <span class="op">=</span> reducer.fit_transform(X)</span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a>    fig_pitch <span class="op">=</span> go.Figure(data<span class="op">=</span>[go.Scatter3d(</span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a>        x<span class="op">=</span>coords[:,<span class="dv">0</span>], y<span class="op">=</span>coords[:,<span class="dv">1</span>], z<span class="op">=</span>coords[:,<span class="dv">2</span>],</span>
<span id="cb35-24"><a href="#cb35-24" aria-hidden="true" tabindex="-1"></a>        mode<span class="op">=</span><span class="st">'markers'</span>,</span>
<span id="cb35-25"><a href="#cb35-25" aria-hidden="true" tabindex="-1"></a>        marker<span class="op">=</span><span class="bu">dict</span>(size<span class="op">=</span><span class="dv">2</span>, color<span class="op">=</span>dy_labels, colorscale<span class="op">=</span><span class="st">'RdBu'</span>, opacity<span class="op">=</span><span class="fl">0.5</span>,</span>
<span id="cb35-26"><a href="#cb35-26" aria-hidden="true" tabindex="-1"></a>                    colorbar<span class="op">=</span><span class="bu">dict</span>(title<span class="op">=</span><span class="st">'dy'</span>)),</span>
<span id="cb35-27"><a href="#cb35-27" aria-hidden="true" tabindex="-1"></a>        hovertext<span class="op">=</span>[<span class="ss">f"dy=</span><span class="sc">{</span>dy<span class="sc">}</span><span class="ss">, dx=</span><span class="sc">{</span>dx<span class="sc">}</span><span class="ss">"</span> <span class="cf">for</span> dy, dx <span class="kw">in</span> <span class="bu">zip</span>(dy_labels, dx_labels)],</span>
<span id="cb35-28"><a href="#cb35-28" aria-hidden="true" tabindex="-1"></a>        hoverinfo<span class="op">=</span><span class="st">'x+y+z+text'</span></span>
<span id="cb35-29"><a href="#cb35-29" aria-hidden="true" tabindex="-1"></a>    )])</span>
<span id="cb35-30"><a href="#cb35-30" aria-hidden="true" tabindex="-1"></a>    fig_pitch.update_layout(title<span class="op">=</span><span class="st">'UMAP 3D — colored by pitch (dy)'</span>, margin<span class="op">=</span><span class="bu">dict</span>(l<span class="op">=</span><span class="dv">0</span>, r<span class="op">=</span><span class="dv">0</span>, b<span class="op">=</span><span class="dv">0</span>, t<span class="op">=</span><span class="dv">30</span>))</span>
<span id="cb35-31"><a href="#cb35-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-32"><a href="#cb35-32" aria-hidden="true" tabindex="-1"></a>    fig_time <span class="op">=</span> go.Figure(data<span class="op">=</span>[go.Scatter3d(</span>
<span id="cb35-33"><a href="#cb35-33" aria-hidden="true" tabindex="-1"></a>        x<span class="op">=</span>coords[:,<span class="dv">0</span>], y<span class="op">=</span>coords[:,<span class="dv">1</span>], z<span class="op">=</span>coords[:,<span class="dv">2</span>],</span>
<span id="cb35-34"><a href="#cb35-34" aria-hidden="true" tabindex="-1"></a>        mode<span class="op">=</span><span class="st">'markers'</span>,</span>
<span id="cb35-35"><a href="#cb35-35" aria-hidden="true" tabindex="-1"></a>        marker<span class="op">=</span><span class="bu">dict</span>(size<span class="op">=</span><span class="dv">2</span>, color<span class="op">=</span>dx_labels, colorscale<span class="op">=</span><span class="st">'PiYG'</span>, opacity<span class="op">=</span><span class="fl">0.5</span>,</span>
<span id="cb35-36"><a href="#cb35-36" aria-hidden="true" tabindex="-1"></a>                    colorbar<span class="op">=</span><span class="bu">dict</span>(title<span class="op">=</span><span class="st">'dx'</span>)),</span>
<span id="cb35-37"><a href="#cb35-37" aria-hidden="true" tabindex="-1"></a>        hovertext<span class="op">=</span>[<span class="ss">f"dy=</span><span class="sc">{</span>dy<span class="sc">}</span><span class="ss">, dx=</span><span class="sc">{</span>dx<span class="sc">}</span><span class="ss">"</span> <span class="cf">for</span> dy, dx <span class="kw">in</span> <span class="bu">zip</span>(dy_labels, dx_labels)],</span>
<span id="cb35-38"><a href="#cb35-38" aria-hidden="true" tabindex="-1"></a>        hoverinfo<span class="op">=</span><span class="st">'x+y+z+text'</span></span>
<span id="cb35-39"><a href="#cb35-39" aria-hidden="true" tabindex="-1"></a>    )])</span>
<span id="cb35-40"><a href="#cb35-40" aria-hidden="true" tabindex="-1"></a>    fig_time.update_layout(title<span class="op">=</span><span class="st">'UMAP 3D — colored by time (dx)'</span>, margin<span class="op">=</span><span class="bu">dict</span>(l<span class="op">=</span><span class="dv">0</span>, r<span class="op">=</span><span class="dv">0</span>, b<span class="op">=</span><span class="dv">0</span>, t<span class="op">=</span><span class="dv">30</span>))</span>
<span id="cb35-41"><a href="#cb35-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-42"><a href="#cb35-42" aria-hidden="true" tabindex="-1"></a>    fig_pitch.show()</span>
<span id="cb35-43"><a href="#cb35-43" aria-hidden="true" tabindex="-1"></a>    fig_time.show()</span>
<span id="cb35-44"><a href="#cb35-44" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> coords, dy_labels, dx_labels</span>
<span id="cb35-45"><a href="#cb35-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-46"><a href="#cb35-46" aria-hidden="true" tabindex="-1"></a>coords, dy_lab, dx_lab <span class="op">=</span> umap_3d_analysis(enc)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/shawley/envs/midi-rae/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11_toy_factorization_files/figure-html/cell-25-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="11_toy_factorization_files/figure-html/cell-25-output-3.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="discussion" class="level2">
<h2 class="anchored" data-anchor-id="discussion">Discussion</h2>
<p>So where are we going with this? The idea that factorization in pitch and time is useful but not the complete picture seems to be borne out and supported by the soft factorization method, which would allow us some level of interpretable controls or structure without forcing it in a detrimental way.</p>
<p>The fact that our augmentation scheme allows us to explicitly label the degree to which we’re Performing the augmentations is a key aspect of this method, i.e., if you were just doing other types of augmentations, you might not be able to pull this off.</p>
<p>I’ll mention that when Christian Steinmetz and I looked at directions for audio effects parameters in latent space (Hawley &amp; Steinmetz, 2023), it was….okay, but ultimately kind of disappointing. Because CLAP embeddings suck. Anyway, this work is kind of on the continuum with that. And the OpLaS paper for letting the latent space encode transformations geometrically.</p>
<p><strong>“Selling Points”:</strong> * I like flexibility of the implementation. It doesn’t require any architecture changes at all as it would if you were going to try to do the factorization by construction. You just add it as a loss term. * Furthermore, it’s tunable. You can sort of weight how strongly you want the factorization thing to take hold just by tuning a regularization parameter in the overall loss term. That’s got to be worth some attention from the machine learning community, right? LOL</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<p><strong>Inspiration: Franck’s series, Soft constraints and kernel methods:</strong> - F. Albinet, “(Part 1) SVD Through Variational Principles: From Geometry to the Classical Formulation,” blog post, Jan 20, 2026. https://fr.anckalbi.net/posts/svd-geometry-to-variational/ - F. Albinet, “(Part 2) Ridges and Thalwegs: The Landscape of Competing Forces — PCA through the LS-SVM lens, preparing the path to SVD and beyond,” blog post, Feb.&nbsp;20, 2026. https://fr.anckalbi.net/posts/ls-svm-kernel-pca/</p>
<p><strong>My Prior Work on Latent Encoding of Data Transformations, Translations, Rotations, Etc:</strong> - S.H. Hawley &amp; A. Tackett, “Operational Latent Spaces (OpLaS),” AES International Symposium on AI and the Musician, https://drscotthawley.github.io/oplas/ - S.H. Hawley &amp; C. J. Steinmetz, “Leveraging Neural Representations for Audio Manipulation,” JAES / AES Europe 2023. https://arxiv.org/abs/2304.04394</p>
<p><strong>Factored representations in symbolic music:</strong> - X. Wu, Z. Huang, K. Zhang, J. Yu, X. Tan, T. Zhang, Y. Li, Z. Wang, and L. Sun, “MelodyGLM: Multi-task Pre-training for Symbolic Melody Generation,” arXiv:2309.10738, September 2023. - K. Chen, G. Xia, and S. Dubnov, “Music SketchNet: Controllable Music Generation via Factorized Representations of Pitch and Rhythm,” arXiv:2008.01291, 2020. - H. Liang, T. Mu, and R. Cai, “PiRhDy: Learning Pitch-, Rhythm-, and Dynamics-aware Embeddings for Symbolic Music,” arXiv:2010.08091, 2020. - Z. Wang, K. Chen, J. Jiang, Y. Zhang, M. Xu, S. Dai, X. Gu, and G. Xia, “MuseBERT: Pre-training Music Representation for Music Understanding and Controllable Generation,” in Proc. ISMIR, 2021.</p>
<p><strong>Motif discovery and pattern repetition:</strong> - D. Meredith, K. Lemström, and G. A. Wiggins, “Algorithms for discovering repeated patterns in multidimensional representations of polyphonic music,” <em>Journal of New Music Research</em>, vol.&nbsp;31, no. 4, pp.&nbsp;321–345, 2002. - D. Meredith, “COSIATEC and SIATECCompress: Pattern discovery by geometric compression,” in MIREX, Curitiba, Brazil, 2013. - E. Cambouropoulos, M. Crochemore, C. Iliopoulos, L. Mouchard, and Y. Pinzon, “Algorithms for computing approximate repetitions in musical sequences,” <em>International Journal of Computer Mathematics</em>, vol.&nbsp;79, no. 11, pp.&nbsp;1135–1148, 2002. - C.-C. M. Yeh, Y. Zhu, L. Ulanova, N. Begum, Y. Ding, H. A. Dau, D. F. Silva, A. Mueen, and E. Keogh, “Matrix Profile I: All pairs similarity joins for time series,” in Proc. IEEE ICDM, Barcelona, Spain, 2016, pp.&nbsp;1317–1322. - “SIATEC-C: Computationally Efficient Repeated Pattern Discovery in Polyphonic Music,” in Proc. ISMIR, 2022. https://archives.ismir.net/ismir2022/paper/000006.pdf</p>
<p><strong>Datasets: (The main code so far is only using POP909).</strong> - Z. Wang, K. Chen, J. Jiang, Y. Zhang, M. Xu, S. Dai, X. Gu, and G. Xia, “POP909: A Pop-song Dataset for Music Arrangement Generation,” in Proc. 21st International Society for Music Information Retrieval Conference (ISMIR), Montréal, Canada, 2020, pp.&nbsp;38–45. - “BPS-Motif: A Dataset for Repeated Pattern Discovery of Polyphonic Symbolic Music,” in Proc. ISMIR, 2023. https://archives.ismir.net/ismir2023/paper/000032.pdf</p>
<p><strong>Representation AutoEncoder (RAE) &amp; more:</strong> - B. Zheng, N. Ma, S. Tong, and S. Xie, “Diffusion Transformers with Representation Autoencoders,” arXiv:2510.11690, 2025. - K. Didi, “The unification of representation learning and generative modelling,” https://kdidi.netlify.app/blog/ml/2025-12-31-r4g/, Dec 31, 2025.</p>
<p><strong>LeJEPA</strong>: - R. Balestriero and Y. LeCun, “LeJEPA: Provable and Scalable Self-Supervised Learning Without the Heuristics”, Nov.&nbsp;2025, https://arxiv.org/abs/2511.08544</p>
<p><strong>Factored representations in transformers:</strong> - A. Shai, L. Amdahl-Culleton, C. L. Christensen, H. R. Bigelow, F. E. Rosas, A. B. Boyd, E. A. Alt, K. J. Ray, and P. M. Riechers, “Transformers learn factored representations,” arXiv:2602.02385, February 2026.</p>
<p><strong>Factored word embeddings:</strong> - J. Pennington, R. Socher, and C. D. Manning, “GloVe: Global Vectors for Word Representation,” in Proc. EMNLP, 2014, pp.&nbsp;1532–1543. https://nlp.stanford.edu/pubs/glove.pdf</p>
<p><strong>Disentangled and geometric representations:</strong> - E. Härkönen, A. Hertzmann, J. Lehtinen, and S. Paris, “GANSpace: Discovering Interpretable GAN Controls,” in Proc. NeurIPS, 2020. - I. Higgins et al., “beta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework,” in Proc. ICLR, 2017. - G. Velarde, D. Meredith, and T. Weyde, “A wavelet-based approach to pattern discovery in melodies,” Springer Cham, 2016, pp.&nbsp;303–333.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/drscotthawley\.github\.io\/midi-rae");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/drscotthawley/midi-rae/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></div></div></footer></body></html>